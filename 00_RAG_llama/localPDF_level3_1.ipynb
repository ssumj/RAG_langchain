{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ë¡œì»¬ í™˜ê²½ì—ì„œ PDF íŒŒì¼ RAG ê²€ìƒ‰í•˜ê¸° 3ë‹¨ê³„ \n",
    "### - ì‚¬ìš©í•œ ì„ë² ë”© ëª¨ë¸ : jhgan/ko-sroberta-multitask\n",
    "### - ì‚¬ìš©í•œ LLM ëª¨ë¸ : llama3.2\n",
    "\n",
    "__step1__\n",
    "- PDF ë¬¸ì„œ ì—¬ëŸ¬ê°œ ë¡œë“œ (data í´ë”ì— ìˆëŠ” ë¬¸ì„œ ì „ë¶€ ë¡œë“œ)\n",
    "- ë¬¸ì„œë¥¼ ì„ë² ë”©í•˜ì—¬ csv íŒŒì¼ë¡œ ì €ì¥ (ì €ì¥ ê²½ë¡œ : csv í´ë”)\n",
    "- csv íŒŒì¼ì„ FAISS ì¸ë±ì‹± : ê²°ê³¼ë¬¼ì´ ì¸ë±ìŠ¤ë¡œ ë‚˜ì˜´\n",
    "- FAISS ì¸ë±ìŠ¤ë¥¼ íŒŒì¼ë¡œ ë§Œë“¤ì–´ ë””ìŠ¤í¬ì— ì €ì¥\n",
    "- ì €ì¥í•œ ì¸ë±ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ ë­ì²´ì¸ í”„ë ˆì„ì›Œí¬ë¥¼ ì ìš©í•˜ì—¬ ê²€ìƒ‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì„ë² ë”© ë°ì´í„°ê°€ csv/SPRI_AI_Brief_2023á„‚á…§á†«12á„‹á…¯á†¯á„’á…©_F.csv íŒŒì¼ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "ì„ë² ë”© ë°ì´í„°ê°€ csv/AIá„€á…µá„‡á…¡á†«_á„‹á…µá†«á„‘á…¡á„‡á…®á†«á„‰á…¥á†¨á„‘á…³á†¯á„…á…¢á†ºá„‘á…©á†·á„€á…®á„á…®á†¨_á„Œá…¦á„‹á…¡á†«á„‰á…¥.csv íŒŒì¼ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "ì„ë² ë”© ë°ì´í„°ê°€ csv/á„‹á…®á†«á„‹á…§á†¼á„á…¦á„Œá…¦_á„Œá…®á†¼á„€á…¡á†«á„€á…ªá„Œá…¦á„†á…®á†¯.csv íŒŒì¼ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "from langchain.document_loaders import DirectoryLoader,PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.docstore.document import Document\n",
    "from langchain_core.embeddings import Embeddings  \n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import csv\n",
    "import faiss\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 1. ë¬¸ì„œ ë¡œë“œ\n",
    "# data í´ë” ì•ˆì— ìˆëŠ” pdf íŒŒì¼ ì „ë¶€ ë¡œë“œí•˜ê¸°\n",
    "loader = DirectoryLoader(\n",
    "    'data',\n",
    "    glob='*.pdf',\n",
    "    loader_cls=PyMuPDFLoader\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "# 2. ë¬¸ì„œ ë¶„í• \n",
    "# í…ìŠ¤íŠ¸ë¥¼ 1000ì ë‹¨ìœ„ë¡œ ë‚˜ëˆ” (chunk size), ê° ì²­í¬ ê°„ 50ìì”© ê²¹ì¹˜ë„ë¡ ì„¤ì •\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)\n",
    "split_documents = text_splitter.split_documents(docs)\n",
    "\n",
    "# 3. ì„ë² ë”©ì„ í•˜ê¸° ìœ„í•œ í´ë˜ìŠ¤ ìƒì„±\n",
    "class KoSentenceTransformerEmbeddings(Embeddings):\n",
    "    # ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™” \n",
    "    def __init__(self, model_name):\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "    # ì—¬ëŸ¬ê°œì˜ ë¬¸ì„œë¥¼ ì„ë² ë”©í•˜ì—¬ ë²¡í„° ë°ì´í„° ìƒì„± , ë²¡í„°í™” ëœ ê° ë¬¸ì„œê°€ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ë°˜í™˜ \n",
    "    def embed_documents(self, texts):\n",
    "        return self.model.encode(texts, convert_to_numpy=True).tolist()\n",
    "    # ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ë²¡í„°í™” \n",
    "    def embed_query(self, text):\n",
    "        return self.model.encode([text], convert_to_numpy=True).tolist()[0]\n",
    "    \n",
    "# 3.1. ì„ë² ë“œ ëª¨ë¸ ë¡œë”©\n",
    "embedding_model = KoSentenceTransformerEmbeddings(\"jhgan/ko-sroberta-multitask\")\n",
    "\n",
    "# 3.2 ë¬¸ì„œë¥¼ ì„ë² ë”© í•˜ì—¬ csv íŒŒì¼ë¡œ ì €ì¥í•˜ê¸° ìœ„í•œ í•¨ìˆ˜ ìƒì„±\n",
    "def save_embeddings_to_csv(documents, embedding_model, file_path):\n",
    "    os.makedirs(file_path, exist_ok=True)\n",
    "\n",
    "    file_docs = {}\n",
    "    for doc in documents:\n",
    "        file_name = os.path.basename(doc.metadata['source']).replace('.pdf','')\n",
    "        if file_name not in file_docs:\n",
    "            file_docs[file_name] = []\n",
    "        file_docs[file_name].append(doc)\n",
    "    \n",
    "    for file_name, docs in file_docs.items():\n",
    "        full_path = os.path.join(file_path, f\"{file_name}.csv\")\n",
    "\n",
    "        #  ì„ë² ë”© \n",
    "        embeddings = embedding_model.embed_documents([doc.page_content for doc in docs])\n",
    "        #  ì„ë² ë”© ê²°ê³¼ë¥¼ CSV ë¡œ ì €ì¥\n",
    "        with open(full_path, mode='w', newline='', encoding='utf-8') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\"document\", \"embedding\"])\n",
    "            \n",
    "            for doc, embedding in zip(docs, embeddings):\n",
    "                writer.writerow([doc.page_content, embedding])\n",
    "        \n",
    "        print(f\"ì„ë² ë”© ë°ì´í„°ê°€ {full_path} íŒŒì¼ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")       \n",
    "    \n",
    "# 3.3 í•¨ìˆ˜ ì‹¤í–‰ í•˜ì—¬ CSV íŒŒì¼ ìƒì„±\n",
    "save_embeddings_to_csv(split_documents, embedding_model, 'csv/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS ì¸ë±ìŠ¤ê°€ ./faiss_index/faiss.index íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!\n",
      "ì €ì¥ëœ FAISS ì¸ë±ìŠ¤ë¥¼ ./faiss_index/faiss.indexì—ì„œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤!\n"
     ]
    }
   ],
   "source": [
    "# 4. ì„ë² ë”© ë°ì´í„°ë¥¼ FAISS ì¸ë±ì‹±í•˜ëŠ” ê³¼ì •\n",
    "# 4.1. CSV íŒŒì¼ì„ ë¡œë“œí•˜ëŠ” í•¨ìˆ˜ \n",
    "def load_embeddings_from_csv(filepath):\n",
    "    df = pd.read_csv(filepath)\n",
    "    # ë¬¸ìì—´ì„ numpy ë°°ì—´ë¡œ ë³€í™˜ \n",
    "    df[\"embedding\"] = df[\"embedding\"].apply(lambda x: np.fromstring(x[1:-1], sep=','))\n",
    "    return df\n",
    "\n",
    "# 4.2. FAISS ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜ \n",
    "def create_faiss_index(df):\n",
    "    embedding_dim = len(df[\"embedding\"].iloc[0])\n",
    "    index = faiss.IndexFlatL2(embedding_dim)  # L2 ê±°ë¦¬ ê¸°ë°˜ ì¸ë±ìŠ¤ ìƒì„±\n",
    "    embeddings = np.vstack(df[\"embedding\"].values).astype(\"float32\")  # numpy ë°°ì—´ ë³€í™˜\n",
    "    index.add(embeddings)  # FAISS ì¸ë±ìŠ¤ì— ë²¡í„° ì¶”ê°€\n",
    "    return index, embedding_dim\n",
    "\n",
    "# 4.3. FAISS ì¸ë±ìŠ¤ë¥¼ ì €ì¥í•˜ëŠ” í•¨ìˆ˜ \n",
    "def save_faiss_index(index, index_filepath):\n",
    "    faiss.write_index(index, index_filepath)\n",
    "    print(f\"FAISS ì¸ë±ìŠ¤ê°€ {index_filepath} íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "\n",
    "\n",
    "# 4.4. FAISS ì¸ë±ìŠ¤ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” í•¨ìˆ˜ \n",
    "def load_faiss_index(index_filepath):\n",
    "    if os.path.exists(index_filepath):\n",
    "        index = faiss.read_index(index_filepath)\n",
    "        print(f\"ì €ì¥ëœ FAISS ì¸ë±ìŠ¤ë¥¼ {index_filepath}ì—ì„œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤!\")\n",
    "        return index\n",
    "    else:\n",
    "        print(f\"{index_filepath} íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\")\n",
    "        return None\n",
    "    \n",
    "# 4.5. í•¨ìˆ˜ ì‹¤í–‰\n",
    "if __name__ == \"__main__\":\n",
    "    csv_filepath = \"./csv/ìš´ì˜ì²´ì œ_ì¤‘ê°„ê³¼ì œë¬¼.csv\"  # CSV íŒŒì¼ ê²½ë¡œ\n",
    "    index_filepath = \"./faiss_index/faiss.index\"  # ì €ì¥í•  FAISS ì¸ë±ìŠ¤ ê²½ë¡œ\n",
    "\n",
    "    # CSVì—ì„œ ì„ë² ë”© ë¡œë“œ\n",
    "    df_embeddings = load_embeddings_from_csv(csv_filepath)\n",
    "\n",
    "    # FAISS ì¸ë±ìŠ¤ ìƒì„±\n",
    "    faiss_index, embedding_dim = create_faiss_index(df_embeddings)\n",
    "\n",
    "    # ì¸ë±ìŠ¤ë¥¼ íŒŒì¼ë¡œ ì €ì¥\n",
    "    os.makedirs(os.path.dirname(index_filepath), exist_ok=True)  # í´ë” ì—†ìœ¼ë©´ ìƒì„±\n",
    "    save_faiss_index(faiss_index, index_filepath)\n",
    "\n",
    "    # ì €ì¥ëœ ì¸ë±ìŠ¤ ë¶ˆëŸ¬ì˜¤ê¸° í…ŒìŠ¤íŠ¸\n",
    "    loaded_faiss_index = load_faiss_index(index_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì €ì¥ëœ FAISS ì¸ë±ìŠ¤ë¥¼ ./faiss_index/faiss.indexì—ì„œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤!\n",
      "\n",
      "ğŸ” ê²€ìƒ‰ ê²°ê³¼:\n",
      "1. ì ìˆ˜: 140.8967\n",
      "   ë¬¸ì„œ: ì¤‘ê°„ê³¼ì œë¬¼ ê³¼ì œëª…\n",
      "2024í•™ë…„ë„ 1í•™ê¸°\n",
      "ê°œì„¤í•™ê³¼\n",
      "ì»´í“¨í„°ê³¼í•™ê³¼\n",
      "êµê³¼ëª©ëª…\n",
      "ìš´ì˜ì²´ì œ\n",
      "ê°œì„¤í•™ë…„\n",
      "3\n",
      "ê³¼ì œìœ í˜•\n",
      "ê³µí†µí˜•\n",
      "[ê³¼ì œëª…]\n",
      "1. ë‹¤ìŒì— ëŒ€í•´ ë‹µí•˜ì‹œì˜¤. (15ì )\n",
      "(1) í”„ë¡œì„¸ìŠ¤ì˜ ë‹¤ì„¯ ê°€ì§€ ìƒíƒœê°€ ë¬´ì—‡ì¸ì§€ ì“°ê³  ê°ê°ì„ ì„¤ëª…í•˜ì‹œì˜¤.\n",
      "(2) ë‹¤ìŒê³¼ ê°™ì€ ìƒí™©ì—ì„œ ë¬¸ì„œ ì‘ì„± í”„ë¡œê·¸ë¨ì˜ í”„ë¡œì„¸ìŠ¤ ìƒíƒœê°€ ì–´ë–»ê²Œ ë³€í™”í•˜ëŠ”ì§€ \n",
      "êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•˜ì‹œì˜¤.\n",
      "ë‚˜ëŠ” ì–´ì œ ì“°ë˜ ë³´ê³ ì„œë¥¼ ë§ˆë¬´ë¦¬í•˜ê¸° ìœ„í•´ ìš°ì„  ë¬¸ì„œ ì‘ì„± í”„ë¡œê·¸ë¨ì„ ì‹¤í–‰ì‹œì¼°ë‹¤. ë©”ë‰´ì—ì„œ íŒŒ\n",
      "ì¼ ì—´ê¸°ë¥¼ ì°¾ì•„ ì‘ì„±í•˜ë˜ ë³´ê³ ì„œ íŒŒì¼ì„ ë¶ˆëŸ¬ì™”ë‹¤. ì‘ì„±í•´ë‘” ë³´ê³ ì„œê°€ ì–‘ì´ ë§ì•„ ë¶ˆëŸ¬ì˜¤ëŠ” ì‹œê°„\n",
      "ì´ ë‹¤ì†Œ ì†Œìš”ë˜ì—ˆë‹¤. ì´í›„ ë³´ê³ ì„œ ì‘ì„±ì„ ë§ˆë¬´ë¦¬í•œ ë’¤ ì €ì¥ ë²„íŠ¼ì„ ëˆŒë €ëŠ”ë° ì—­ì‹œ ëª‡ ì´ˆì˜ ì‹œê°„\n",
      "ì´ ì§€ë‚œ í›„ì—ì•¼ ì €ì¥ì´ ì™„ë£Œë˜ì—ˆë‹¤. ì´ì œ ë³´ê³ ì„œ ì‘ì—…ì´ ëë‚¬ê¸°ì— ë©”ë‰´ì—ì„œ ì¢…ë£Œ ë²„íŠ¼ì„ ì°¾ì•„ \n",
      "ë¬¸ì„œ ì‘ì„± í”„ë¡œê·¸ë¨ ì°½ì„ ë‹«ì•˜ë‹¤.\n",
      "2. í”„ë¡œì„¸ìŠ¤ë³„ ë„ì°©ì‹œê°ê³¼ í•„ìš”í•œ CPU ì‚¬ì´í´ì´ í‘œì™€ ê°™ì„ ë•Œ, ë‹¤ìŒì— ëŒ€í•´ ë‹µí•˜ì‹œì˜¤. \n",
      "ë‹¨, ëª¨ë“  ë‹µì•ˆì€ ê·¼ê±°(ê³¼ì •ì— ëŒ€í•œ ì„¤ëª…, ê³„ì‚°ì‹ ë“±)ê°€ í•¨ê»˜ ì œì‹œë˜ì–´ì•¼ í•œë‹¤. (15ì )\n",
      "      \n",
      "í”„ë¡œì„¸ìŠ¤\n",
      "A\n",
      "B\n",
      "C\n",
      "D\n",
      "E\n",
      "ë„ì°©ì‹œê°\n",
      "0\n",
      "2\n",
      "5\n",
      "6\n",
      "7\n",
      "CPU ì‚¬ì´í´\n",
      "4\n",
      "3\n",
      "1\n",
      "5\n",
      "2\n",
      "(1) SJF ìŠ¤ì¼€ì¤„ë§ê³¼ HRN ìŠ¤ì¼€ì¤„ë§ ì¤‘ í•˜ë‚˜ë§Œ ì„ íƒí•˜ì—¬, ì„ íƒí•œ ìŠ¤ì¼€ì¤„ë§ ì•Œê³ ë¦¬ì¦˜ì— ì˜í•´ \n",
      "í”„ë¡œì„¸ìŠ¤ë“¤ì´ ìˆ˜í–‰ë˜ëŠ” ìˆœì„œë¥¼ êµ¬ì²´ì ì¸ ì‹œê°ê³¼ í•¨ê»˜ í‘œì‹œí•˜ì‹œì˜¤.\n",
      "(2) (1)ì˜ ê²°ê³¼ì— ëŒ€í•´ ê° í”„ë¡œì„¸ìŠ¤ì˜ ë°˜í™˜ì‹œê°„ì„ êµ¬í•˜ê³ , í‰ê· ë°˜í™˜ì‹œê°„ì„ ê³„ì‚°í•˜ì‹œì˜¤.\n",
      "(3) SRT ìŠ¤ì¼€ì¤„ë§ê³¼ RR ìŠ¤ì¼€ì¤„ë§(ì‹œê°„ í• ë‹¹ëŸ‰=3) ì¤‘ í•˜ë‚˜ë§Œ ì´ìš©í•˜ì—¬ í”„ë¡œì„¸ìŠ¤ë“¤ì´ ìˆ˜í–‰\n",
      "ë˜ëŠ” ìˆœì„œì™€ ì‹œê°, ê° í”„ë¡œì„¸ìŠ¤ì˜ ë°˜í™˜ì‹œê°„, ë‹¤ì„¯ í”„ë¡œì„¸ìŠ¤ì˜ í‰ê· ë°˜í™˜ì‹œê°„ì„ êµ¬í•˜ì‹œì˜¤.\n",
      "[ê³¼ì œì‘ì„± ì‹œ ì§€ì‹œì‚¬í•­] : ì‘ì„±ì„œì‹, ë¶„ëŸ‰, ì œì¶œë°©ë²•, ë³´ì¡°íŒŒì¼ ì‚¬ìš© ì—¬ë¶€ ë“± ê¸°ìˆ \n",
      " - ì œì¶œíŒŒì¼ ì¢…ë¥˜: í•œê¸€, MS-Word íŒŒì¼, ë˜ëŠ” í…ìŠ¤íŠ¸ ì¶”ì¶œ ê°€ëŠ¥í•œ PDF\n",
      " - íŒŒì¼ ìš©ëŸ‰ì€ 5MB ì´ë‚´ë¡œ í•˜ê³ , ê¸€ìí¬ê¸° 11pt\n",
      " - ì‘ì„± ë¶„ëŸ‰: í‘œì§€ í¬í•¨ 5ìª½ ì´í•˜(A4ê¸°ì¤€)\n",
      " - ê³¼ì œëª…ì„ ì œì™¸í•˜ê³  ë¬¸í•­ë²ˆí˜¸ì™€ ë‹µì•ˆë§Œ ì‘ì„±\n",
      "\n",
      "2. ì ìˆ˜: 152.5155\n",
      "   ë¬¸ì„œ: - ê³¼ì œëª…ì„ ì œì™¸í•˜ê³  ë¬¸í•­ë²ˆí˜¸ì™€ ë‹µì•ˆë§Œ ì‘ì„±\n",
      " - 2ë²ˆ ê³¼ì œì—ì„œ ì‹œê°ë³„ í”„ë¡œì„¸ìŠ¤ë“¤ì˜ ìˆ˜í–‰ ìˆœì„œëŠ” ê·¸ë¦¼ìœ¼ë¡œ ë‚˜íƒ€ë‚´ëŠ” ê²ƒì´ ê°€ëŠ¥í•˜ì§€ë§Œ, \n",
      "ê·¸ì— ëŒ€í•œ ì„¤ëª…ì€ ë°˜ë“œì‹œ í…ìŠ¤íŠ¸ë¡œ ì‘ì„±í•  ê²ƒ\n",
      " - ì°¸ê³ ë¬¸í—Œì€ ì‘ì„±í•  í•„ìš” ì—†ìŒ\n",
      " - í‘œì ˆë¥ ì´ ë†’ìœ¼ë©´ ê°ì  ì²˜ë¦¬í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ, êµì¬ë‚˜ ê°•ì˜ì˜ ë‚´ìš©ì„ ê·¸ëŒ€ë¡œ ì˜®ê¸°ì§€ ë§ê³  \n",
      "ë³¸ì¸ì˜ ì´í•´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìì‹ ë§Œì˜ í‘œí˜„ìœ¼ë¡œ ì„œìˆ í•  ê²ƒ\n",
      " - ë¹ˆ íŒŒì¼, í‘œì§€ë§Œ ìˆëŠ” íŒŒì¼, íƒ€ ê³¼ëª© ê³¼ì œë¬¼ íŒŒì¼ ë“±ì„ ì œì¶œí•  ê²½ìš° 0ì  ì²˜ë¦¬ë˜ë¯€ë¡œ \n",
      "ê³¼ì œë¬¼ ì œì¶œ ì§í›„ ë°˜ë“œì‹œ í™•ì¸í•  ê²ƒ\n",
      " - ê³¼ì œëª… ê´€ë ¨ ë¬¸ì˜ì²˜: https://www.knou.ac.kr/jwkim/8460/subview.do\n",
      "\n",
      "3. ì ìˆ˜: 340282346638528859811704183484516925440.0000\n",
      "   ë¬¸ì„œ: - ê³¼ì œëª…ì„ ì œì™¸í•˜ê³  ë¬¸í•­ë²ˆí˜¸ì™€ ë‹µì•ˆë§Œ ì‘ì„±\n",
      " - 2ë²ˆ ê³¼ì œì—ì„œ ì‹œê°ë³„ í”„ë¡œì„¸ìŠ¤ë“¤ì˜ ìˆ˜í–‰ ìˆœì„œëŠ” ê·¸ë¦¼ìœ¼ë¡œ ë‚˜íƒ€ë‚´ëŠ” ê²ƒì´ ê°€ëŠ¥í•˜ì§€ë§Œ, \n",
      "ê·¸ì— ëŒ€í•œ ì„¤ëª…ì€ ë°˜ë“œì‹œ í…ìŠ¤íŠ¸ë¡œ ì‘ì„±í•  ê²ƒ\n",
      " - ì°¸ê³ ë¬¸í—Œì€ ì‘ì„±í•  í•„ìš” ì—†ìŒ\n",
      " - í‘œì ˆë¥ ì´ ë†’ìœ¼ë©´ ê°ì  ì²˜ë¦¬í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ, êµì¬ë‚˜ ê°•ì˜ì˜ ë‚´ìš©ì„ ê·¸ëŒ€ë¡œ ì˜®ê¸°ì§€ ë§ê³  \n",
      "ë³¸ì¸ì˜ ì´í•´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìì‹ ë§Œì˜ í‘œí˜„ìœ¼ë¡œ ì„œìˆ í•  ê²ƒ\n",
      " - ë¹ˆ íŒŒì¼, í‘œì§€ë§Œ ìˆëŠ” íŒŒì¼, íƒ€ ê³¼ëª© ê³¼ì œë¬¼ íŒŒì¼ ë“±ì„ ì œì¶œí•  ê²½ìš° 0ì  ì²˜ë¦¬ë˜ë¯€ë¡œ \n",
      "ê³¼ì œë¬¼ ì œì¶œ ì§í›„ ë°˜ë“œì‹œ í™•ì¸í•  ê²ƒ\n",
      " - ê³¼ì œëª… ê´€ë ¨ ë¬¸ì˜ì²˜: https://www.knou.ac.kr/jwkim/8460/subview.do\n",
      "\n",
      "4. ì ìˆ˜: 340282346638528859811704183484516925440.0000\n",
      "   ë¬¸ì„œ: - ê³¼ì œëª…ì„ ì œì™¸í•˜ê³  ë¬¸í•­ë²ˆí˜¸ì™€ ë‹µì•ˆë§Œ ì‘ì„±\n",
      " - 2ë²ˆ ê³¼ì œì—ì„œ ì‹œê°ë³„ í”„ë¡œì„¸ìŠ¤ë“¤ì˜ ìˆ˜í–‰ ìˆœì„œëŠ” ê·¸ë¦¼ìœ¼ë¡œ ë‚˜íƒ€ë‚´ëŠ” ê²ƒì´ ê°€ëŠ¥í•˜ì§€ë§Œ, \n",
      "ê·¸ì— ëŒ€í•œ ì„¤ëª…ì€ ë°˜ë“œì‹œ í…ìŠ¤íŠ¸ë¡œ ì‘ì„±í•  ê²ƒ\n",
      " - ì°¸ê³ ë¬¸í—Œì€ ì‘ì„±í•  í•„ìš” ì—†ìŒ\n",
      " - í‘œì ˆë¥ ì´ ë†’ìœ¼ë©´ ê°ì  ì²˜ë¦¬í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ, êµì¬ë‚˜ ê°•ì˜ì˜ ë‚´ìš©ì„ ê·¸ëŒ€ë¡œ ì˜®ê¸°ì§€ ë§ê³  \n",
      "ë³¸ì¸ì˜ ì´í•´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìì‹ ë§Œì˜ í‘œí˜„ìœ¼ë¡œ ì„œìˆ í•  ê²ƒ\n",
      " - ë¹ˆ íŒŒì¼, í‘œì§€ë§Œ ìˆëŠ” íŒŒì¼, íƒ€ ê³¼ëª© ê³¼ì œë¬¼ íŒŒì¼ ë“±ì„ ì œì¶œí•  ê²½ìš° 0ì  ì²˜ë¦¬ë˜ë¯€ë¡œ \n",
      "ê³¼ì œë¬¼ ì œì¶œ ì§í›„ ë°˜ë“œì‹œ í™•ì¸í•  ê²ƒ\n",
      " - ê³¼ì œëª… ê´€ë ¨ ë¬¸ì˜ì²˜: https://www.knou.ac.kr/jwkim/8460/subview.do\n",
      "\n",
      "5. ì ìˆ˜: 340282346638528859811704183484516925440.0000\n",
      "   ë¬¸ì„œ: - ê³¼ì œëª…ì„ ì œì™¸í•˜ê³  ë¬¸í•­ë²ˆí˜¸ì™€ ë‹µì•ˆë§Œ ì‘ì„±\n",
      " - 2ë²ˆ ê³¼ì œì—ì„œ ì‹œê°ë³„ í”„ë¡œì„¸ìŠ¤ë“¤ì˜ ìˆ˜í–‰ ìˆœì„œëŠ” ê·¸ë¦¼ìœ¼ë¡œ ë‚˜íƒ€ë‚´ëŠ” ê²ƒì´ ê°€ëŠ¥í•˜ì§€ë§Œ, \n",
      "ê·¸ì— ëŒ€í•œ ì„¤ëª…ì€ ë°˜ë“œì‹œ í…ìŠ¤íŠ¸ë¡œ ì‘ì„±í•  ê²ƒ\n",
      " - ì°¸ê³ ë¬¸í—Œì€ ì‘ì„±í•  í•„ìš” ì—†ìŒ\n",
      " - í‘œì ˆë¥ ì´ ë†’ìœ¼ë©´ ê°ì  ì²˜ë¦¬í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ, êµì¬ë‚˜ ê°•ì˜ì˜ ë‚´ìš©ì„ ê·¸ëŒ€ë¡œ ì˜®ê¸°ì§€ ë§ê³  \n",
      "ë³¸ì¸ì˜ ì´í•´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìì‹ ë§Œì˜ í‘œí˜„ìœ¼ë¡œ ì„œìˆ í•  ê²ƒ\n",
      " - ë¹ˆ íŒŒì¼, í‘œì§€ë§Œ ìˆëŠ” íŒŒì¼, íƒ€ ê³¼ëª© ê³¼ì œë¬¼ íŒŒì¼ ë“±ì„ ì œì¶œí•  ê²½ìš° 0ì  ì²˜ë¦¬ë˜ë¯€ë¡œ \n",
      "ê³¼ì œë¬¼ ì œì¶œ ì§í›„ ë°˜ë“œì‹œ í™•ì¸í•  ê²ƒ\n",
      " - ê³¼ì œëª… ê´€ë ¨ ë¬¸ì˜ì²˜: https://www.knou.ac.kr/jwkim/8460/subview.do\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 5. ì €ì¥ëœ ì¸ë±ìŠ¤ íŒŒì¼ + csv íŒŒì¼ì„ ì½ì–´ì„œ ê²€ìƒ‰ì„ í•˜ëŠ” ê³¼ì •\n",
    "# ë‹µë³€ì„ ìì—°ì–´ë¡œ ì£¼ê¸° ìœ„í•´ì„œëŠ” csv íŒŒì¼ë„ ê°™ì´ ë¡œë“œí•´ì•¼í•¨\n",
    "import faiss\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 5.1. ì €ì¥ëœ FAISS ì¸ë±ìŠ¤ ë¡œë“œí•˜ëŠ” í•¨ìˆ˜\n",
    "def load_faiss_index(index_filepath):\n",
    "    index = faiss.read_index(index_filepath)\n",
    "    print(f\"ì €ì¥ëœ FAISS ì¸ë±ìŠ¤ë¥¼ {index_filepath}ì—ì„œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤!\")\n",
    "    return index\n",
    "\n",
    "# 5.2. CSVì—ì„œ ë¬¸ì„œ ë¡œë“œ (ë¬¸ì„œ ì›ë³¸ ë°ì´í„° í•„ìš”) í•˜ëŠ” í•¨ìˆ˜ \n",
    "def load_documents_from_csv(csv_filepath):\n",
    "    df = pd.read_csv(csv_filepath)\n",
    "    return df[\"document\"].tolist()  # ë¬¸ì„œ ì›ë³¸ í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜\n",
    "\n",
    "# 5.3. FAISSì—ì„œ ìœ ì‚¬í•œ ë¬¸ì„œ ê²€ìƒ‰í•˜ëŠ” í•¨ìˆ˜ \n",
    "def search_faiss(index, query_embedding, documents, top_k=5):\n",
    "    query_embedding = np.array([query_embedding], dtype=np.float32)  # FAISS ì…ë ¥ í˜•ì‹ ë³€í™˜\n",
    "    distances, indices = index.search(query_embedding, top_k)  # ê°€ì¥ ê°€ê¹Œìš´ top_kê°œ ê²€ìƒ‰\n",
    "    \n",
    "    results = []\n",
    "    for i in range(top_k):\n",
    "        idx = indices[0][i]\n",
    "        results.append((documents[idx], distances[0][i]))  # (ë¬¸ì„œ, ê±°ë¦¬)\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# 5.4. í•¨ìˆ˜ ì‹¤í–‰ \n",
    "if __name__ == \"__main__\":\n",
    "    index_filepath = \"./faiss_index/faiss.index\"  # ì €ì¥ëœ FAISS ì¸ë±ìŠ¤ íŒŒì¼ ê²½ë¡œ\n",
    "    csv_filepath = \"./csv/ìš´ì˜ì²´ì œ_ì¤‘ê°„ê³¼ì œë¬¼.csv\"  # ì›ë³¸ ë¬¸ì„œê°€ ì €ì¥ëœ CSV íŒŒì¼ ê²½ë¡œ\n",
    "\n",
    "    # FAISS ì¸ë±ìŠ¤ ë¡œë“œ\n",
    "    faiss_index = load_faiss_index(index_filepath)\n",
    "\n",
    "    # ë¬¸ì„œ ì›ë³¸ ë°ì´í„° ë¡œë“œ\n",
    "    documents = load_documents_from_csv(csv_filepath)\n",
    "\n",
    "    # ê²€ìƒ‰ì–´ ì…ë ¥ ë° ì„ë² ë”© ë³€í™˜\n",
    "    query_text = \"ì–´ë”” í•™ê³¼ì˜ ê³µì§€ì‚¬í•­ì…ë‹ˆê¹Œ?\"\n",
    "    query_embedding = embedding_model.embed_query(query_text)\n",
    "\n",
    "    # FAISS ê²€ìƒ‰ ì‹¤í–‰\n",
    "    results = search_faiss(faiss_index, query_embedding, documents, top_k=5)\n",
    "\n",
    "    # ê²€ìƒ‰ ê²°ê³¼ ì¶œë ¥\n",
    "    print(\"\\nğŸ” ê²€ìƒ‰ ê²°ê³¼:\")\n",
    "    for rank, (doc, score) in enumerate(results, start=1):\n",
    "        print(f\"{rank}. ì ìˆ˜: {score:.4f}\\n   ë¬¸ì„œ: {doc}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. í”„ë¡¬í”„íŠ¸ ìƒì„± \n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the question. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "Answer in Korean,and make sure the answer ends with 'ì…ë‹ˆë‹¤'.\n",
    "\n",
    "#Context: \n",
    "{context}\n",
    "\n",
    "#Question:\n",
    "{question}\n",
    "\n",
    "#Answer(Ensure the response ends with 'ì…ë‹ˆë‹¤'):\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
