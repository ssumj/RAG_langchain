{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 로컬 환경에서 PDF 파일 RAG 검색하기 3단계\n",
    "\n",
    "__step5__\n",
    "- PDF 문서 여러개 로드하여 임베딩 후 csv 파일로 저장\n",
    "- csv 파일을 랭체인 FAISS 인덱싱하여 인덱스 파일 생성 및 저장\n",
    "- 랭체인 프레임워크 적용하여 llm 검색 까지 구현\n",
    "- 파일 3개 인덱싱 후 1개 추가하여 llm 검색 하기 구현\n",
    "\n",
    "- 추가 파일 인덱스 병합하지 않고 각각 저장하는 코드 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 임베딩 데이터가 csv/SPRI_AI_Brief_2023년12월호_F.csv 파일에 저장되었습니다.\n",
      "✅ 임베딩 데이터가 csv/AI기반_인파분석플랫폼구축_제안서.csv 파일에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import json\n",
    "import ast\n",
    "import faiss\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from langchain.document_loaders import DirectoryLoader, PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.docstore.document import Document\n",
    "from langchain_core.embeddings import Embeddings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# 1. 문서 로드\n",
    "loader = DirectoryLoader(\n",
    "    'data',\n",
    "    glob='*.pdf',\n",
    "    loader_cls=PyMuPDFLoader\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "# 2. 문서 분할\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)\n",
    "split_documents = text_splitter.split_documents(docs)\n",
    "\n",
    "# 3. 임베딩을 위한 클래스 생성\n",
    "class KoSentenceTransformerEmbeddings(Embeddings):\n",
    "    def __init__(self, model_name):\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "    \n",
    "    def embed_documents(self, texts):\n",
    "        return self.model.encode(texts, convert_to_numpy=True).tolist()\n",
    "    \n",
    "    def embed_query(self, text):\n",
    "        return self.model.encode([text], convert_to_numpy=True).tolist()[0]\n",
    "\n",
    "# 임베딩 모델\n",
    "embedding_model = KoSentenceTransformerEmbeddings(\"jhgan/ko-sroberta-multitask\")\n",
    "\n",
    "# 4. 임베딩 저장 함수\n",
    "def save_embeddings_to_csv(documents, embedding_model, folder_path):\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "    \n",
    "    file_docs = {}\n",
    "    for doc in documents:\n",
    "        file_name = os.path.basename(doc.metadata['source']).replace('.pdf', '')\n",
    "        if file_name not in file_docs:\n",
    "            file_docs[file_name] = []\n",
    "        file_docs[file_name].append(doc)\n",
    "    \n",
    "    for file_name, docs in file_docs.items():\n",
    "        full_path = os.path.join(folder_path, f\"{file_name}.csv\")\n",
    "        \n",
    "        embeddings = embedding_model.embed_documents([doc.page_content for doc in docs])\n",
    "        \n",
    "        with open(full_path, mode='w', newline='', encoding='utf-8') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\"document\", \"embedding\"])\n",
    "            \n",
    "            for doc, embedding in zip(docs, embeddings):\n",
    "                writer.writerow([doc.page_content, json.dumps(embedding)])  # JSON 형식으로 저장\n",
    "        \n",
    "        print(f\"✅ 임베딩 데이터가 {full_path} 파일에 저장되었습니다.\")\n",
    "\n",
    "# 임베딩 저장 함수 실행\n",
    "save_embeddings_to_csv(split_documents, embedding_model, 'csv/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. CSV에서 임베딩 로드 및 FAISS 인덱스 생성\n",
    "def load_csv_embeddings(folder_path):\n",
    "    data_dict = {}\n",
    "    \n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            df = pd.read_csv(file_path)\n",
    "            \n",
    "            if \"document\" in df.columns and \"embedding\" in df.columns:\n",
    "                documents, embeddings, metadatas = [], [], []\n",
    "                for _, row in df.iterrows():\n",
    "                    text = row[\"document\"]\n",
    "                    try:\n",
    "                        embedding = json.loads(row[\"embedding\"])  # JSON 로드 방식으로 변경\n",
    "                        if isinstance(embedding, list):\n",
    "                            embeddings.append(np.array(embedding, dtype=np.float32))\n",
    "                            documents.append(text)\n",
    "                            metadatas.append({\"source\": filename})\n",
    "                        else:\n",
    "                            print(f\"⚠️ {filename}의 임베딩 형식이 올바르지 않습니다!\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"⚠️ {filename}에서 임베딩 변환 오류: {e}\")\n",
    "                data_dict[filename.replace('.csv', '')] = (documents, embeddings, metadatas)\n",
    "    \n",
    "    return data_dict\n",
    "\n",
    "# FAISS 인덱스 생성 및 저장\n",
    "def create_faiss_indexes(data_dict, save_path):\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    \n",
    "    for file_name, (documents, embeddings, metadatas) in data_dict.items():\n",
    "        vector_store = FAISS.from_texts(texts=documents, embedding=embedding_model, metadatas=metadatas)\n",
    "        faiss_index_path = os.path.join(save_path, file_name)\n",
    "        vector_store.save_local(faiss_index_path)\n",
    "        print(f\"✅ {file_name}에 대한 FAISS 인덱스 저장 완료: {faiss_index_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📄 2개의 파일 로드 완료!\n",
      "✅ SPRI_AI_Brief_2023년12월호_F에 대한 FAISS 인덱스 저장 완료: ./faiss_index/SPRI_AI_Brief_2023년12월호_F\n",
      "✅ AI기반_인파분석플랫폼구축_제안서에 대한 FAISS 인덱스 저장 완료: ./faiss_index/AI기반_인파분석플랫폼구축_제안서\n"
     ]
    }
   ],
   "source": [
    "# 실행\n",
    "if __name__ == \"__main__\":\n",
    "    data_folder = \"./csv\"\n",
    "    faiss_index_folder = \"./faiss_index\"\n",
    "    \n",
    "    data_dict = load_csv_embeddings(data_folder)\n",
    "    print(f\"📄 {len(data_dict)}개의 파일 로드 완료!\")\n",
    "    \n",
    "    if data_dict:\n",
    "        create_faiss_indexes(data_dict, faiss_index_folder)\n",
    "    else:\n",
    "        print(\"⚠️ 문서 또는 임베딩 데이터가 없습니다. FAISS 인덱스를 생성할 수 없습니다!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ SPRI_AI_Brief_2023년12월호_F 인덱스 로드 완료!\n",
      "✅ AI기반_인파분석플랫폼구축_제안서 인덱스 로드 완료!\n",
      "✅ 답변: 챌레오입니다.\n",
      "📁 출처:\n",
      "SPRI_AI_Brief_2023년12월호_F\n",
      "AI기반_인파분석플랫폼구축_제안서\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "\n",
    "# ✅ Step 6: 프롬프트 생성\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the question. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "Answer in Korean, and make sure the answer ends with '입니다'.\n",
    "\n",
    "#Context: \n",
    "{context}\n",
    "\n",
    "#Question:\n",
    "{question}\n",
    "\n",
    "#Answer(Ensure the response ends with '입니다'):\"\"\"\n",
    ")\n",
    "\n",
    "# Step 7: 언어 모델 (LLM) 생성\n",
    "llm = Ollama(model=\"llama3.2\")  \n",
    "\n",
    "\n",
    "# ✅ Step 4: 모든 FAISS 인덱스를 로드하는 함수\n",
    "def load_all_faiss_indexes(index_folder):\n",
    "    faiss_indexes = {}\n",
    "\n",
    "    for file_name in os.listdir(index_folder):\n",
    "        index_path = os.path.join(index_folder, file_name)\n",
    "        if os.path.isdir(index_path):  # 폴더 형태의 FAISS 인덱스인지 확인\n",
    "            try:\n",
    "                faiss_indexes[file_name] = FAISS.load_local(\n",
    "                    index_path,\n",
    "                    embedding_model,\n",
    "                    allow_dangerous_deserialization=True  # 보안 옵션 추가\n",
    "                )\n",
    "                print(f\"✅ {file_name} 인덱스 로드 완료!\")\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ {file_name} 인덱스 로드 실패: {e}\")\n",
    "    \n",
    "    return faiss_indexes\n",
    "\n",
    "# ✅ Step 5: 모든 FAISS 인덱스를 검색하는 함수\n",
    "def search_across_all_indexes(question, faiss_indexes, top_k=5):\n",
    "    all_docs = []\n",
    "\n",
    "    # 모든 FAISS 인덱스에서 검색\n",
    "    for index_name, index in faiss_indexes.items():\n",
    "        retriever = index.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": top_k})\n",
    "        docs = retriever.get_relevant_documents(question)  \n",
    "\n",
    "        # 문서 출처 정보 추가\n",
    "        for doc in docs:\n",
    "            doc.metadata[\"source\"] = index_name\n",
    "        all_docs.extend(docs)\n",
    "\n",
    "    if not all_docs:\n",
    "        return \"❌ 관련 문서를 찾을 수 없습니다.\"\n",
    "\n",
    "    # ✅ Step 6: 검색된 문서들을 기반으로 컨텍스트 생성\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in all_docs])\n",
    "    \n",
    "    # ✅ Step 7: LLM을 사용해 답변 생성\n",
    "    formatted_prompt = prompt.format(context=context, question=question)\n",
    "    answer = llm.invoke(formatted_prompt)\n",
    "\n",
    "    # ✅ Step 8: 검색된 문서들의 출처 정리\n",
    "    sources = \"\\n\".join(set([doc.metadata.get(\"source\", \"알 수 없음\") for doc in all_docs]))\n",
    "\n",
    "    return f\"✅ 답변: {answer.strip()}\\n📁 출처:\\n{sources}\"\n",
    "\n",
    "# ✅ 실행 코드\n",
    "if __name__ == \"__main__\":\n",
    "    faiss_index_folder = \"./faiss_index\"  # FAISS 인덱스 저장 폴더\n",
    "    question = \"삼성전자가 만든 AI의 이름은?\"\n",
    "\n",
    "    # ✅ Step 1: 모든 FAISS 인덱스 로드\n",
    "    faiss_indexes = load_all_faiss_indexes(faiss_index_folder)\n",
    "\n",
    "    # ✅ Step 2: 질문 수행\n",
    "    response = search_across_all_indexes(question, faiss_indexes)\n",
    "    \n",
    "    # ✅ Step 3: 결과 출력\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 '삼성에서 만든 AI의 이름은 무엇인가?' 검색 결과:\n",
      "1. SPRi AI Brief |  \n",
      "2023-12월호\n",
      "10\n",
      "삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개\n",
      "n 삼성전자가 온디바이스에서 작동 가능하며 언어, 코드, 이미지의 3개 모델로 구성된 자체 개발 생성 \n",
      "AI 모델 ‘삼성 가우스’를 공개\n",
      "n 삼성전자는 삼성 가우스를 다양한 제품에 단계적으로 탑재할 계획으로, 온디바이스 작동이 가능한 \n",
      "삼성 가우스는 외부로 사용자 정보가 유출될 위험이 없다는 장점을 보유\n",
      "KEY Contents\n",
      "£ 언어, 코드, 이미지의 3개 모델로 구성된 삼성 가우스, 온디바이스 작동 지원\n",
      "n 삼성전자가 2023년 11월 8일 열린 ‘삼성 AI 포럼 2023’ 행사에서 자체 개발한 생성 AI 모델 \n",
      "‘삼성 가우스’를 최초 공개\n",
      "∙정규분포 이론을 정립한 천재 수학자 가우스(Gauss)의 이름을 본뜬 삼성 가우스는 다양한 상황에 \n",
      "최적화된 크기의 모델 선택이 가능\n",
      "∙삼성 가우스는 라이선스나 개인정보를 침해하지 않는 안전한 데이터를 통해 학습되었으며, \n",
      "온디바이스에서 작동하도록 설계되어 외부로 사용자의 정보가 유출되지 않는 장점을 보유\n",
      "∙삼성전자는 삼성 가우스를 활용한 온디바이스 AI 기술도 소개했으며, 생성 AI 모델을 다양한 제품에 \n",
      "단계적으로 탑재할 계획\n",
      "n 삼성 가우스는 △텍스트를 생성하는 언어모델 △코드를 생성하는 코드 모델 △이미지를 생성하는 \n",
      "이미지 모델의 3개 모델로 구성\n",
      "∙언어 모델은 클라우드와 온디바이스 대상 다양한 모델로 구성되며, 메일 작성, 문서 요약, 번역 업무의 \n",
      "처리를 지원\n",
      "∙코드 모델 기반의 AI 코딩 어시스턴트 ‘코드아이(code.i)’는 대화형 인터페이스로 서비스를 제공하며 \n",
      "사내 소프트웨어 개발에 최적화\n",
      "∙이미지 모델은 창의적인 이미지를 생성하고 기존 이미지를 원하는 대로 바꿀 수 있도록 지원하며 \n",
      "저해상도 이미지의 고해상도 전환도 지원\n",
      "n IT 전문지 테크리퍼블릭(TechRepublic)은 온디바이스 AI가 주요 기술 트렌드로 부상했다며, (출처: SPRI_AI_Brief_2023년12월호_F.csv)\n",
      "2. 2024년부터 가우스를 탑재한 삼성 스마트폰이 메타의 라마(Llama)2를 탑재한 퀄컴 기기 및 구글 \n",
      "어시스턴트를 적용한 구글 픽셀(Pixel)과 경쟁할 것으로 예상\n",
      "☞ 출처 : 삼성전자, ‘삼성 AI 포럼’서 자체 개발 생성형 AI ‘삼성 가우스’ 공개, 2023.11.08.\n",
      "삼성전자, ‘삼성 개발자 콘퍼런스 코리아 2023’ 개최, 2023.11.14.\n",
      "TechRepublic, Samsung Gauss: Samsung Research Reveals Generative AI, 2023.11.08. (출처: SPRI_AI_Brief_2023년12월호_F.csv)\n",
      "3. 통한 기업 고객의 클라우드 지출 확대를 위해 AI 투자를 지속  \n",
      "∙구글은 앤스로픽 외에도 AI 동영상 제작 도구를 개발하는 런웨이(Runway)와 오픈소스 소프트웨어 \n",
      "기업 허깅 페이스(Hugging Face)에도 투자\n",
      "∙구글은 챗GPT의 기반 기술과 직접 경쟁할 수 있는 차세대 LLM ‘제미니(Gemini)’를 포함한 자체 AI \n",
      "시스템 개발에도 수십억 달러를 투자했으며, 2024년 제미니를 출시할 계획\n",
      "☞ 출처 : The Wall Street Journal, Google Commits $2 Billion in Funding to AI Startup Anthropic, 2023.10.27.\n",
      "Bloomberg, AI Startup Anthropic to Use Google Chips in Expanded Partnership, 2023.11.09. (출처: SPRI_AI_Brief_2023년12월호_F.csv)\n",
      "4. 16\n",
      "구글 딥마인드, 범용 AI 모델의 기능과 동작에 대한 분류 체계 발표\n",
      "n 구글 딥마인드 연구진이 성능과 범용성, 자율성을 기준으로 범용 AI(AGI)의 수준을 \n",
      "0~5단계까지 총 6단계로 구분한 프레임워크를 공개\n",
      "n 현재 AGI는 단백질 구조를 예측하는 알파폴드와 같은 특정 용도에서는 5단계 수준을 달성했지만 \n",
      "광범위하게 활용될 수 있는 범용에서는 1단계 수준에 머물러 있음\n",
      "KEY Contents\n",
      "£ 챗GPT와 구글 바드와 같은 AI 챗봇은 범용 AI 1단계 수준\n",
      "n 구글 딥마인드 연구진은 2023년 11월 4일 범용 AI(Artificial General Intelligence, AGI) 모델을 용도와 \n",
      "성능에 따라 분류하는 프레임워크를 제시한 논문을 발표\n",
      "∙프레임워크의 목적은 AGI의 성능, 범용성, 자율성 수준을 정의하여 모델 간 비교와 위험 평가, AGI \n",
      "달성까지의 진행 상황을 측정할 수 있는 공통 기준을 제공하기 위함\n",
      "n 연구진은 AGI 개념 정의에 필요한 기준을 수립하기 위한 6가지 원칙을 아래와 같이 도출\n",
      "∙(프로세스가 아닌 기능에 중점) AI가 어떻게 작동하는지보다 무엇을 할 수 있는지가 더 중요\n",
      "∙(범용성과 성능을 모두 평가) 진정한 AGI는 인간을 능가하는 폭넓은 범용성과 기술의 깊이를 모두 요구\n",
      "∙(인지와 메타인지 작업에 중점) 물리적 작업의 수행 능력은 AGI의 필수 전제조건이 아니며, 인지 작업과 \n",
      "메타인지 작업(예; 새로운 작업의 학습 능력, 인간에게 도움을 요청할 시점을 아는 능력)이 핵심\n",
      "∙(실제 구현보다 잠재력에 집중) 통제된 상황에서 발휘되는 성능에 따라 AGI를 규정하고 테스트를 진행 \n",
      "∙(생태학적 타당도를 갖춘 벤치마크 사용) AGI에 대한 벤치마크는 사람들이 경제적· 사회적 또는 예술적으로 \n",
      "가치 있게 여기는 실질적인 작업을 대상으로 성능 평가 필요\n",
      "∙(종점이 아닌 AGI를 향한 경로에 중점) 단계별 접근방식을 통해 AGI의 발전 상태를 점진적으로 측정 (출처: SPRI_AI_Brief_2023년12월호_F.csv)\n",
      "5. n 연구진은 상기 원칙에 따라 AI를 성능에 따라 0~5단계와 광범위한 목적에 활용될 수 있는 범용 AI 및 특정 \n",
      "과업에 활용되는 특수 AI로 분류했으며, 특수 AI에서는 5단계까지 달성되었으나, 범용 AI는 현재 1단계 수준\n",
      "성능\n",
      "특수 AI 예시\n",
      "범용 AI 예시\n",
      "0단계: AI 아님\n",
      "계산기 소프트웨어, 컴파일러\n",
      "아마존 메커니컬 터크\n",
      "1단계: 신진(숙련되지 않은 인간)\n",
      "GOFAI(Good Old Fashioned Artificial Intelligence) \n",
      "챗GPT, 바드, 라마2\n",
      "2단계: 유능(숙련된 인간의 50% 이상)\n",
      "스마트 스피커(애플 시리, 아마존 알렉사, 구글 \n",
      "어시스턴트), IBM 왓슨 \n",
      "미달성\n",
      "3단계: 전문가(숙련된 인간의 90% 이상)\n",
      "문법 교정기(그래머리), 생성 이미지 모델(달리2)\n",
      "미달성\n",
      "4단계: 거장(숙련된 인간의 99% 이상) \n",
      "딥블루, 알파고\n",
      "미달성\n",
      "5단계: 초인간(인간을 100% 능가)\n",
      "알파폴드, 알파제로, 스톡피시\n",
      "미달성\n",
      "<구글 딥마인드의 범용 AI 분류 프레임워크> \n",
      "☞ 출처 : Arxiv.org, Levels of AGI: Operationalizing Progress on the Path to AGI, 2023.11.04. (출처: SPRI_AI_Brief_2023년12월호_F.csv)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(id='35bbb80f-2959-4bfd-b489-0afd3a96506f', metadata={'source': 'SPRI_AI_Brief_2023년12월호_F.csv'}, page_content='SPRi AI Brief |  \\n2023-12월호\\n10\\n삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개\\nn 삼성전자가 온디바이스에서 작동 가능하며 언어, 코드, 이미지의 3개 모델로 구성된 자체 개발 생성 \\nAI 모델 ‘삼성 가우스’를 공개\\nn 삼성전자는 삼성 가우스를 다양한 제품에 단계적으로 탑재할 계획으로, 온디바이스 작동이 가능한 \\n삼성 가우스는 외부로 사용자 정보가 유출될 위험이 없다는 장점을 보유\\nKEY Contents\\n£ 언어, 코드, 이미지의 3개 모델로 구성된 삼성 가우스, 온디바이스 작동 지원\\nn 삼성전자가 2023년 11월 8일 열린 ‘삼성 AI 포럼 2023’ 행사에서 자체 개발한 생성 AI 모델 \\n‘삼성 가우스’를 최초 공개\\n∙정규분포 이론을 정립한 천재 수학자 가우스(Gauss)의 이름을 본뜬 삼성 가우스는 다양한 상황에 \\n최적화된 크기의 모델 선택이 가능\\n∙삼성 가우스는 라이선스나 개인정보를 침해하지 않는 안전한 데이터를 통해 학습되었으며, \\n온디바이스에서 작동하도록 설계되어 외부로 사용자의 정보가 유출되지 않는 장점을 보유\\n∙삼성전자는 삼성 가우스를 활용한 온디바이스 AI 기술도 소개했으며, 생성 AI 모델을 다양한 제품에 \\n단계적으로 탑재할 계획\\nn 삼성 가우스는 △텍스트를 생성하는 언어모델 △코드를 생성하는 코드 모델 △이미지를 생성하는 \\n이미지 모델의 3개 모델로 구성\\n∙언어 모델은 클라우드와 온디바이스 대상 다양한 모델로 구성되며, 메일 작성, 문서 요약, 번역 업무의 \\n처리를 지원\\n∙코드 모델 기반의 AI 코딩 어시스턴트 ‘코드아이(code.i)’는 대화형 인터페이스로 서비스를 제공하며 \\n사내 소프트웨어 개발에 최적화\\n∙이미지 모델은 창의적인 이미지를 생성하고 기존 이미지를 원하는 대로 바꿀 수 있도록 지원하며 \\n저해상도 이미지의 고해상도 전환도 지원\\nn IT 전문지 테크리퍼블릭(TechRepublic)은 온디바이스 AI가 주요 기술 트렌드로 부상했다며,'),\n",
       " Document(id='15a4fec5-fecb-4c1a-aa6f-e253a509152f', metadata={'source': 'SPRI_AI_Brief_2023년12월호_F.csv'}, page_content='2024년부터 가우스를 탑재한 삼성 스마트폰이 메타의 라마(Llama)2를 탑재한 퀄컴 기기 및 구글 \\n어시스턴트를 적용한 구글 픽셀(Pixel)과 경쟁할 것으로 예상\\n☞ 출처 : 삼성전자, ‘삼성 AI 포럼’서 자체 개발 생성형 AI ‘삼성 가우스’ 공개, 2023.11.08.\\n삼성전자, ‘삼성 개발자 콘퍼런스 코리아 2023’ 개최, 2023.11.14.\\nTechRepublic, Samsung Gauss: Samsung Research Reveals Generative AI, 2023.11.08.'),\n",
       " Document(id='7b1d8bd5-85d6-4254-a291-5e27011d92d3', metadata={'source': 'SPRI_AI_Brief_2023년12월호_F.csv'}, page_content='통한 기업 고객의 클라우드 지출 확대를 위해 AI 투자를 지속  \\n∙구글은 앤스로픽 외에도 AI 동영상 제작 도구를 개발하는 런웨이(Runway)와 오픈소스 소프트웨어 \\n기업 허깅 페이스(Hugging Face)에도 투자\\n∙구글은 챗GPT의 기반 기술과 직접 경쟁할 수 있는 차세대 LLM ‘제미니(Gemini)’를 포함한 자체 AI \\n시스템 개발에도 수십억 달러를 투자했으며, 2024년 제미니를 출시할 계획\\n☞ 출처 : The Wall Street Journal, Google Commits $2 Billion in Funding to AI Startup Anthropic, 2023.10.27.\\nBloomberg, AI Startup Anthropic to Use Google Chips in Expanded Partnership, 2023.11.09.'),\n",
       " Document(id='23e36641-f712-404c-aead-c0a6d920dfda', metadata={'source': 'SPRI_AI_Brief_2023년12월호_F.csv'}, page_content='16\\n구글 딥마인드, 범용 AI 모델의 기능과 동작에 대한 분류 체계 발표\\nn 구글 딥마인드 연구진이 성능과 범용성, 자율성을 기준으로 범용 AI(AGI)의 수준을 \\n0~5단계까지 총 6단계로 구분한 프레임워크를 공개\\nn 현재 AGI는 단백질 구조를 예측하는 알파폴드와 같은 특정 용도에서는 5단계 수준을 달성했지만 \\n광범위하게 활용될 수 있는 범용에서는 1단계 수준에 머물러 있음\\nKEY Contents\\n£ 챗GPT와 구글 바드와 같은 AI 챗봇은 범용 AI 1단계 수준\\nn 구글 딥마인드 연구진은 2023년 11월 4일 범용 AI(Artificial General Intelligence, AGI) 모델을 용도와 \\n성능에 따라 분류하는 프레임워크를 제시한 논문을 발표\\n∙프레임워크의 목적은 AGI의 성능, 범용성, 자율성 수준을 정의하여 모델 간 비교와 위험 평가, AGI \\n달성까지의 진행 상황을 측정할 수 있는 공통 기준을 제공하기 위함\\nn 연구진은 AGI 개념 정의에 필요한 기준을 수립하기 위한 6가지 원칙을 아래와 같이 도출\\n∙(프로세스가 아닌 기능에 중점) AI가 어떻게 작동하는지보다 무엇을 할 수 있는지가 더 중요\\n∙(범용성과 성능을 모두 평가) 진정한 AGI는 인간을 능가하는 폭넓은 범용성과 기술의 깊이를 모두 요구\\n∙(인지와 메타인지 작업에 중점) 물리적 작업의 수행 능력은 AGI의 필수 전제조건이 아니며, 인지 작업과 \\n메타인지 작업(예; 새로운 작업의 학습 능력, 인간에게 도움을 요청할 시점을 아는 능력)이 핵심\\n∙(실제 구현보다 잠재력에 집중) 통제된 상황에서 발휘되는 성능에 따라 AGI를 규정하고 테스트를 진행 \\n∙(생태학적 타당도를 갖춘 벤치마크 사용) AGI에 대한 벤치마크는 사람들이 경제적· 사회적 또는 예술적으로 \\n가치 있게 여기는 실질적인 작업을 대상으로 성능 평가 필요\\n∙(종점이 아닌 AGI를 향한 경로에 중점) 단계별 접근방식을 통해 AGI의 발전 상태를 점진적으로 측정'),\n",
       " Document(id='4be36b13-892d-4d3c-bc98-b38f8dbcf537', metadata={'source': 'SPRI_AI_Brief_2023년12월호_F.csv'}, page_content='n 연구진은 상기 원칙에 따라 AI를 성능에 따라 0~5단계와 광범위한 목적에 활용될 수 있는 범용 AI 및 특정 \\n과업에 활용되는 특수 AI로 분류했으며, 특수 AI에서는 5단계까지 달성되었으나, 범용 AI는 현재 1단계 수준\\n성능\\n특수 AI 예시\\n범용 AI 예시\\n0단계: AI 아님\\n계산기 소프트웨어, 컴파일러\\n아마존 메커니컬 터크\\n1단계: 신진(숙련되지 않은 인간)\\nGOFAI(Good Old Fashioned Artificial Intelligence) \\n챗GPT, 바드, 라마2\\n2단계: 유능(숙련된 인간의 50% 이상)\\n스마트 스피커(애플 시리, 아마존 알렉사, 구글 \\n어시스턴트), IBM 왓슨 \\n미달성\\n3단계: 전문가(숙련된 인간의 90% 이상)\\n문법 교정기(그래머리), 생성 이미지 모델(달리2)\\n미달성\\n4단계: 거장(숙련된 인간의 99% 이상) \\n딥블루, 알파고\\n미달성\\n5단계: 초인간(인간을 100% 능가)\\n알파폴드, 알파제로, 스톡피시\\n미달성\\n<구글 딥마인드의 범용 AI 분류 프레임워크> \\n☞ 출처 : Arxiv.org, Levels of AGI: Operationalizing Progress on the Path to AGI, 2023.11.04.')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def search_faiss_index(query, index_folder, file_name, top_k=5):\n",
    "    index_path = os.path.join(index_folder, file_name)\n",
    "    \n",
    "    # FAISS 인덱스 로드 시 allow_dangerous_deserialization 옵션 추가\n",
    "    vector_store = FAISS.load_local(index_path, embedding_model, allow_dangerous_deserialization=True)\n",
    "    \n",
    "    query_embedding = embedding_model.embed_query(query)\n",
    "    results = vector_store.similarity_search_by_vector(query_embedding, k=top_k)\n",
    "    \n",
    "    print(f\"🔍 '{query}' 검색 결과:\")\n",
    "    for i, result in enumerate(results):\n",
    "        print(f\"{i+1}. {result.page_content} (출처: {result.metadata['source']})\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# search_faiss_index(\"포항에서 열리는 축제의 이름은 무엇인가?\", \"./faiss_index\", \"AI기반_인파분석플랫폼구축_제안서\")\n",
    "search_faiss_index(\"삼성에서 만든 AI의 이름은 무엇인가?\", \"./faiss_index\", \"SPRI_AI_Brief_2023년12월호_F\")\n",
    "# search_faiss_index(\"경기도 인구정책사업에서 현행 유지 평가를 받은 사업의 개수는?\", \"./faiss_index\", \"2024년 경기도 인구영향평가_편집본\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
