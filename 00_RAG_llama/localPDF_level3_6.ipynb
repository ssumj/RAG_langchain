{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ë¡œì»¬ í™˜ê²½ì—ì„œ PDF íŒŒì¼ RAG ê²€ìƒ‰í•˜ê¸° 3ë‹¨ê³„\n",
    "\n",
    "__step5__\n",
    "- PDF ë¬¸ì„œ ì—¬ëŸ¬ê°œ ë¡œë“œí•˜ì—¬ ì„ë² ë”© í›„ csv íŒŒì¼ë¡œ ì €ì¥\n",
    "- csv íŒŒì¼ì„ ë­ì²´ì¸ FAISS ì¸ë±ì‹±í•˜ì—¬ ì¸ë±ìŠ¤ íŒŒì¼ ìƒì„± ë° ì €ì¥\n",
    "- ë­ì²´ì¸ í”„ë ˆì„ì›Œí¬ ì ìš©í•˜ì—¬ llm ê²€ìƒ‰ ê¹Œì§€ êµ¬í˜„\n",
    "- íŒŒì¼ 3ê°œ ì¸ë±ì‹± í›„ 1ê°œ ì¶”ê°€í•˜ì—¬ llm ê²€ìƒ‰ í•˜ê¸° êµ¬í˜„\n",
    "\n",
    "- ì¶”ê°€ íŒŒì¼ ì¸ë±ìŠ¤ ë³‘í•©í•˜ì§€ ì•Šê³  ê°ê° ì €ì¥í•˜ëŠ” ì½”ë“œ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì„ë² ë”© ë°ì´í„°ê°€ csv/SPRI_AI_Brief_2023á„‚á…§á†«12á„‹á…¯á†¯á„’á…©_F.csv íŒŒì¼ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "âœ… ì„ë² ë”© ë°ì´í„°ê°€ csv/AIá„€á…µá„‡á…¡á†«_á„‹á…µá†«á„‘á…¡á„‡á…®á†«á„‰á…¥á†¨á„‘á…³á†¯á„…á…¢á†ºá„‘á…©á†·á„€á…®á„á…®á†¨_á„Œá…¦á„‹á…¡á†«á„‰á…¥.csv íŒŒì¼ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import json\n",
    "import ast\n",
    "import faiss\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from langchain.document_loaders import DirectoryLoader, PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.docstore.document import Document\n",
    "from langchain_core.embeddings import Embeddings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# 1. ë¬¸ì„œ ë¡œë“œ\n",
    "loader = DirectoryLoader(\n",
    "    'data',\n",
    "    glob='*.pdf',\n",
    "    loader_cls=PyMuPDFLoader\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "# 2. ë¬¸ì„œ ë¶„í• \n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)\n",
    "split_documents = text_splitter.split_documents(docs)\n",
    "\n",
    "# 3. ì„ë² ë”©ì„ ìœ„í•œ í´ë˜ìŠ¤ ìƒì„±\n",
    "class KoSentenceTransformerEmbeddings(Embeddings):\n",
    "    def __init__(self, model_name):\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "    \n",
    "    def embed_documents(self, texts):\n",
    "        return self.model.encode(texts, convert_to_numpy=True).tolist()\n",
    "    \n",
    "    def embed_query(self, text):\n",
    "        return self.model.encode([text], convert_to_numpy=True).tolist()[0]\n",
    "\n",
    "# ì„ë² ë”© ëª¨ë¸\n",
    "embedding_model = KoSentenceTransformerEmbeddings(\"jhgan/ko-sroberta-multitask\")\n",
    "\n",
    "# 4. ì„ë² ë”© ì €ì¥ í•¨ìˆ˜\n",
    "def save_embeddings_to_csv(documents, embedding_model, folder_path):\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "    \n",
    "    file_docs = {}\n",
    "    for doc in documents:\n",
    "        file_name = os.path.basename(doc.metadata['source']).replace('.pdf', '')\n",
    "        if file_name not in file_docs:\n",
    "            file_docs[file_name] = []\n",
    "        file_docs[file_name].append(doc)\n",
    "    \n",
    "    for file_name, docs in file_docs.items():\n",
    "        full_path = os.path.join(folder_path, f\"{file_name}.csv\")\n",
    "        \n",
    "        embeddings = embedding_model.embed_documents([doc.page_content for doc in docs])\n",
    "        \n",
    "        with open(full_path, mode='w', newline='', encoding='utf-8') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\"document\", \"embedding\"])\n",
    "            \n",
    "            for doc, embedding in zip(docs, embeddings):\n",
    "                writer.writerow([doc.page_content, json.dumps(embedding)])  # JSON í˜•ì‹ìœ¼ë¡œ ì €ì¥\n",
    "        \n",
    "        print(f\"âœ… ì„ë² ë”© ë°ì´í„°ê°€ {full_path} íŒŒì¼ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# ì„ë² ë”© ì €ì¥ í•¨ìˆ˜ ì‹¤í–‰\n",
    "save_embeddings_to_csv(split_documents, embedding_model, 'csv/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. CSVì—ì„œ ì„ë² ë”© ë¡œë“œ ë° FAISS ì¸ë±ìŠ¤ ìƒì„±\n",
    "def load_csv_embeddings(folder_path):\n",
    "    data_dict = {}\n",
    "    \n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            df = pd.read_csv(file_path)\n",
    "            \n",
    "            if \"document\" in df.columns and \"embedding\" in df.columns:\n",
    "                documents, embeddings, metadatas = [], [], []\n",
    "                for _, row in df.iterrows():\n",
    "                    text = row[\"document\"]\n",
    "                    try:\n",
    "                        embedding = json.loads(row[\"embedding\"])  # JSON ë¡œë“œ ë°©ì‹ìœ¼ë¡œ ë³€ê²½\n",
    "                        if isinstance(embedding, list):\n",
    "                            embeddings.append(np.array(embedding, dtype=np.float32))\n",
    "                            documents.append(text)\n",
    "                            metadatas.append({\"source\": filename})\n",
    "                        else:\n",
    "                            print(f\"âš ï¸ {filename}ì˜ ì„ë² ë”© í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤!\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"âš ï¸ {filename}ì—ì„œ ì„ë² ë”© ë³€í™˜ ì˜¤ë¥˜: {e}\")\n",
    "                data_dict[filename.replace('.csv', '')] = (documents, embeddings, metadatas)\n",
    "    \n",
    "    return data_dict\n",
    "\n",
    "# FAISS ì¸ë±ìŠ¤ ìƒì„± ë° ì €ì¥\n",
    "def create_faiss_indexes(data_dict, save_path):\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    \n",
    "    for file_name, (documents, embeddings, metadatas) in data_dict.items():\n",
    "        vector_store = FAISS.from_texts(texts=documents, embedding=embedding_model, metadatas=metadatas)\n",
    "        faiss_index_path = os.path.join(save_path, file_name)\n",
    "        vector_store.save_local(faiss_index_path)\n",
    "        print(f\"âœ… {file_name}ì— ëŒ€í•œ FAISS ì¸ë±ìŠ¤ ì €ì¥ ì™„ë£Œ: {faiss_index_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“„ 2ê°œì˜ íŒŒì¼ ë¡œë“œ ì™„ë£Œ!\n",
      "âœ… SPRI_AI_Brief_2023á„‚á…§á†«12á„‹á…¯á†¯á„’á…©_Fì— ëŒ€í•œ FAISS ì¸ë±ìŠ¤ ì €ì¥ ì™„ë£Œ: ./faiss_index/SPRI_AI_Brief_2023á„‚á…§á†«12á„‹á…¯á†¯á„’á…©_F\n",
      "âœ… AIá„€á…µá„‡á…¡á†«_á„‹á…µá†«á„‘á…¡á„‡á…®á†«á„‰á…¥á†¨á„‘á…³á†¯á„…á…¢á†ºá„‘á…©á†·á„€á…®á„á…®á†¨_á„Œá…¦á„‹á…¡á†«á„‰á…¥ì— ëŒ€í•œ FAISS ì¸ë±ìŠ¤ ì €ì¥ ì™„ë£Œ: ./faiss_index/AIá„€á…µá„‡á…¡á†«_á„‹á…µá†«á„‘á…¡á„‡á…®á†«á„‰á…¥á†¨á„‘á…³á†¯á„…á…¢á†ºá„‘á…©á†·á„€á…®á„á…®á†¨_á„Œá…¦á„‹á…¡á†«á„‰á…¥\n"
     ]
    }
   ],
   "source": [
    "# ì‹¤í–‰\n",
    "if __name__ == \"__main__\":\n",
    "    data_folder = \"./csv\"\n",
    "    faiss_index_folder = \"./faiss_index\"\n",
    "    \n",
    "    data_dict = load_csv_embeddings(data_folder)\n",
    "    print(f\"ğŸ“„ {len(data_dict)}ê°œì˜ íŒŒì¼ ë¡œë“œ ì™„ë£Œ!\")\n",
    "    \n",
    "    if data_dict:\n",
    "        create_faiss_indexes(data_dict, faiss_index_folder)\n",
    "    else:\n",
    "        print(\"âš ï¸ ë¬¸ì„œ ë˜ëŠ” ì„ë² ë”© ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. FAISS ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… SPRI_AI_Brief_2023á„‚á…§á†«12á„‹á…¯á†¯á„’á…©_F ì¸ë±ìŠ¤ ë¡œë“œ ì™„ë£Œ!\n",
      "âœ… AIá„€á…µá„‡á…¡á†«_á„‹á…µá†«á„‘á…¡á„‡á…®á†«á„‰á…¥á†¨á„‘á…³á†¯á„…á…¢á†ºá„‘á…©á†·á„€á…®á„á…®á†¨_á„Œá…¦á„‹á…¡á†«á„‰á…¥ ì¸ë±ìŠ¤ ë¡œë“œ ì™„ë£Œ!\n",
      "âœ… ë‹µë³€: ì±Œë ˆì˜¤ì…ë‹ˆë‹¤.\n",
      "ğŸ“ ì¶œì²˜:\n",
      "SPRI_AI_Brief_2023á„‚á…§á†«12á„‹á…¯á†¯á„’á…©_F\n",
      "AIá„€á…µá„‡á…¡á†«_á„‹á…µá†«á„‘á…¡á„‡á…®á†«á„‰á…¥á†¨á„‘á…³á†¯á„…á…¢á†ºá„‘á…©á†·á„€á…®á„á…®á†¨_á„Œá…¦á„‹á…¡á†«á„‰á…¥\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "\n",
    "# âœ… Step 6: í”„ë¡¬í”„íŠ¸ ìƒì„±\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the question. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "Answer in Korean, and make sure the answer ends with 'ì…ë‹ˆë‹¤'.\n",
    "\n",
    "#Context: \n",
    "{context}\n",
    "\n",
    "#Question:\n",
    "{question}\n",
    "\n",
    "#Answer(Ensure the response ends with 'ì…ë‹ˆë‹¤'):\"\"\"\n",
    ")\n",
    "\n",
    "# Step 7: ì–¸ì–´ ëª¨ë¸ (LLM) ìƒì„±\n",
    "llm = Ollama(model=\"llama3.2\")  \n",
    "\n",
    "\n",
    "# âœ… Step 4: ëª¨ë“  FAISS ì¸ë±ìŠ¤ë¥¼ ë¡œë“œí•˜ëŠ” í•¨ìˆ˜\n",
    "def load_all_faiss_indexes(index_folder):\n",
    "    faiss_indexes = {}\n",
    "\n",
    "    for file_name in os.listdir(index_folder):\n",
    "        index_path = os.path.join(index_folder, file_name)\n",
    "        if os.path.isdir(index_path):  # í´ë” í˜•íƒœì˜ FAISS ì¸ë±ìŠ¤ì¸ì§€ í™•ì¸\n",
    "            try:\n",
    "                faiss_indexes[file_name] = FAISS.load_local(\n",
    "                    index_path,\n",
    "                    embedding_model,\n",
    "                    allow_dangerous_deserialization=True  # ë³´ì•ˆ ì˜µì…˜ ì¶”ê°€\n",
    "                )\n",
    "                print(f\"âœ… {file_name} ì¸ë±ìŠ¤ ë¡œë“œ ì™„ë£Œ!\")\n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸ {file_name} ì¸ë±ìŠ¤ ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "    \n",
    "    return faiss_indexes\n",
    "\n",
    "# âœ… Step 5: ëª¨ë“  FAISS ì¸ë±ìŠ¤ë¥¼ ê²€ìƒ‰í•˜ëŠ” í•¨ìˆ˜\n",
    "def search_across_all_indexes(question, faiss_indexes, top_k=5):\n",
    "    all_docs = []\n",
    "\n",
    "    # ëª¨ë“  FAISS ì¸ë±ìŠ¤ì—ì„œ ê²€ìƒ‰\n",
    "    for index_name, index in faiss_indexes.items():\n",
    "        retriever = index.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": top_k})\n",
    "        docs = retriever.get_relevant_documents(question)  \n",
    "\n",
    "        # ë¬¸ì„œ ì¶œì²˜ ì •ë³´ ì¶”ê°€\n",
    "        for doc in docs:\n",
    "            doc.metadata[\"source\"] = index_name\n",
    "        all_docs.extend(docs)\n",
    "\n",
    "    if not all_docs:\n",
    "        return \"âŒ ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "\n",
    "    # âœ… Step 6: ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì„ ê¸°ë°˜ìœ¼ë¡œ ì»¨í…ìŠ¤íŠ¸ ìƒì„±\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in all_docs])\n",
    "    \n",
    "    # âœ… Step 7: LLMì„ ì‚¬ìš©í•´ ë‹µë³€ ìƒì„±\n",
    "    formatted_prompt = prompt.format(context=context, question=question)\n",
    "    answer = llm.invoke(formatted_prompt)\n",
    "\n",
    "    # âœ… Step 8: ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì˜ ì¶œì²˜ ì •ë¦¬\n",
    "    sources = \"\\n\".join(set([doc.metadata.get(\"source\", \"ì•Œ ìˆ˜ ì—†ìŒ\") for doc in all_docs]))\n",
    "\n",
    "    return f\"âœ… ë‹µë³€: {answer.strip()}\\nğŸ“ ì¶œì²˜:\\n{sources}\"\n",
    "\n",
    "# âœ… ì‹¤í–‰ ì½”ë“œ\n",
    "if __name__ == \"__main__\":\n",
    "    faiss_index_folder = \"./faiss_index\"  # FAISS ì¸ë±ìŠ¤ ì €ì¥ í´ë”\n",
    "    question = \"ì‚¼ì„±ì „ìê°€ ë§Œë“  AIì˜ ì´ë¦„ì€?\"\n",
    "\n",
    "    # âœ… Step 1: ëª¨ë“  FAISS ì¸ë±ìŠ¤ ë¡œë“œ\n",
    "    faiss_indexes = load_all_faiss_indexes(faiss_index_folder)\n",
    "\n",
    "    # âœ… Step 2: ì§ˆë¬¸ ìˆ˜í–‰\n",
    "    response = search_across_all_indexes(question, faiss_indexes)\n",
    "    \n",
    "    # âœ… Step 3: ê²°ê³¼ ì¶œë ¥\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” 'ì‚¼ì„±ì—ì„œ ë§Œë“  AIì˜ ì´ë¦„ì€ ë¬´ì—‡ì¸ê°€?' ê²€ìƒ‰ ê²°ê³¼:\n",
      "1. SPRi AI Brief |  \n",
      "2023-12ì›”í˜¸\n",
      "10\n",
      "ì‚¼ì„±ì „ì, ìì²´ ê°œë°œ ìƒì„± AI â€˜ì‚¼ì„± ê°€ìš°ìŠ¤â€™ ê³µê°œ\n",
      "n ì‚¼ì„±ì „ìê°€ ì˜¨ë””ë°”ì´ìŠ¤ì—ì„œ ì‘ë™ ê°€ëŠ¥í•˜ë©° ì–¸ì–´, ì½”ë“œ, ì´ë¯¸ì§€ì˜ 3ê°œ ëª¨ë¸ë¡œ êµ¬ì„±ëœ ìì²´ ê°œë°œ ìƒì„± \n",
      "AI ëª¨ë¸ â€˜ì‚¼ì„± ê°€ìš°ìŠ¤â€™ë¥¼ ê³µê°œ\n",
      "n ì‚¼ì„±ì „ìëŠ” ì‚¼ì„± ê°€ìš°ìŠ¤ë¥¼ ë‹¤ì–‘í•œ ì œí’ˆì— ë‹¨ê³„ì ìœ¼ë¡œ íƒ‘ì¬í•  ê³„íšìœ¼ë¡œ, ì˜¨ë””ë°”ì´ìŠ¤ ì‘ë™ì´ ê°€ëŠ¥í•œ \n",
      "ì‚¼ì„± ê°€ìš°ìŠ¤ëŠ” ì™¸ë¶€ë¡œ ì‚¬ìš©ì ì •ë³´ê°€ ìœ ì¶œë  ìœ„í—˜ì´ ì—†ë‹¤ëŠ” ì¥ì ì„ ë³´ìœ \n",
      "KEY Contents\n",
      "Â£ ì–¸ì–´, ì½”ë“œ, ì´ë¯¸ì§€ì˜ 3ê°œ ëª¨ë¸ë¡œ êµ¬ì„±ëœ ì‚¼ì„± ê°€ìš°ìŠ¤, ì˜¨ë””ë°”ì´ìŠ¤ ì‘ë™ ì§€ì›\n",
      "n ì‚¼ì„±ì „ìê°€ 2023ë…„ 11ì›” 8ì¼ ì—´ë¦° â€˜ì‚¼ì„± AI í¬ëŸ¼ 2023â€™ í–‰ì‚¬ì—ì„œ ìì²´ ê°œë°œí•œ ìƒì„± AI ëª¨ë¸ \n",
      "â€˜ì‚¼ì„± ê°€ìš°ìŠ¤â€™ë¥¼ ìµœì´ˆ ê³µê°œ\n",
      "âˆ™ì •ê·œë¶„í¬ ì´ë¡ ì„ ì •ë¦½í•œ ì²œì¬ ìˆ˜í•™ì ê°€ìš°ìŠ¤(Gauss)ì˜ ì´ë¦„ì„ ë³¸ëœ¬ ì‚¼ì„± ê°€ìš°ìŠ¤ëŠ” ë‹¤ì–‘í•œ ìƒí™©ì— \n",
      "ìµœì í™”ëœ í¬ê¸°ì˜ ëª¨ë¸ ì„ íƒì´ ê°€ëŠ¥\n",
      "âˆ™ì‚¼ì„± ê°€ìš°ìŠ¤ëŠ” ë¼ì´ì„ ìŠ¤ë‚˜ ê°œì¸ì •ë³´ë¥¼ ì¹¨í•´í•˜ì§€ ì•ŠëŠ” ì•ˆì „í•œ ë°ì´í„°ë¥¼ í†µí•´ í•™ìŠµë˜ì—ˆìœ¼ë©°, \n",
      "ì˜¨ë””ë°”ì´ìŠ¤ì—ì„œ ì‘ë™í•˜ë„ë¡ ì„¤ê³„ë˜ì–´ ì™¸ë¶€ë¡œ ì‚¬ìš©ìì˜ ì •ë³´ê°€ ìœ ì¶œë˜ì§€ ì•ŠëŠ” ì¥ì ì„ ë³´ìœ \n",
      "âˆ™ì‚¼ì„±ì „ìëŠ” ì‚¼ì„± ê°€ìš°ìŠ¤ë¥¼ í™œìš©í•œ ì˜¨ë””ë°”ì´ìŠ¤ AI ê¸°ìˆ ë„ ì†Œê°œí–ˆìœ¼ë©°, ìƒì„± AI ëª¨ë¸ì„ ë‹¤ì–‘í•œ ì œí’ˆì— \n",
      "ë‹¨ê³„ì ìœ¼ë¡œ íƒ‘ì¬í•  ê³„íš\n",
      "n ì‚¼ì„± ê°€ìš°ìŠ¤ëŠ” â–³í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ì–¸ì–´ëª¨ë¸ â–³ì½”ë“œë¥¼ ìƒì„±í•˜ëŠ” ì½”ë“œ ëª¨ë¸ â–³ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ëŠ” \n",
      "ì´ë¯¸ì§€ ëª¨ë¸ì˜ 3ê°œ ëª¨ë¸ë¡œ êµ¬ì„±\n",
      "âˆ™ì–¸ì–´ ëª¨ë¸ì€ í´ë¼ìš°ë“œì™€ ì˜¨ë””ë°”ì´ìŠ¤ ëŒ€ìƒ ë‹¤ì–‘í•œ ëª¨ë¸ë¡œ êµ¬ì„±ë˜ë©°, ë©”ì¼ ì‘ì„±, ë¬¸ì„œ ìš”ì•½, ë²ˆì—­ ì—…ë¬´ì˜ \n",
      "ì²˜ë¦¬ë¥¼ ì§€ì›\n",
      "âˆ™ì½”ë“œ ëª¨ë¸ ê¸°ë°˜ì˜ AI ì½”ë”© ì–´ì‹œìŠ¤í„´íŠ¸ â€˜ì½”ë“œì•„ì´(code.i)â€™ëŠ” ëŒ€í™”í˜• ì¸í„°í˜ì´ìŠ¤ë¡œ ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•˜ë©° \n",
      "ì‚¬ë‚´ ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œì— ìµœì í™”\n",
      "âˆ™ì´ë¯¸ì§€ ëª¨ë¸ì€ ì°½ì˜ì ì¸ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ê³  ê¸°ì¡´ ì´ë¯¸ì§€ë¥¼ ì›í•˜ëŠ” ëŒ€ë¡œ ë°”ê¿€ ìˆ˜ ìˆë„ë¡ ì§€ì›í•˜ë©° \n",
      "ì €í•´ìƒë„ ì´ë¯¸ì§€ì˜ ê³ í•´ìƒë„ ì „í™˜ë„ ì§€ì›\n",
      "n IT ì „ë¬¸ì§€ í…Œí¬ë¦¬í¼ë¸”ë¦­(TechRepublic)ì€ ì˜¨ë””ë°”ì´ìŠ¤ AIê°€ ì£¼ìš” ê¸°ìˆ  íŠ¸ë Œë“œë¡œ ë¶€ìƒí–ˆë‹¤ë©°, (ì¶œì²˜: SPRI_AI_Brief_2023á„‚á…§á†«12á„‹á…¯á†¯á„’á…©_F.csv)\n",
      "2. 2024ë…„ë¶€í„° ê°€ìš°ìŠ¤ë¥¼ íƒ‘ì¬í•œ ì‚¼ì„± ìŠ¤ë§ˆíŠ¸í°ì´ ë©”íƒ€ì˜ ë¼ë§ˆ(Llama)2ë¥¼ íƒ‘ì¬í•œ í€„ì»´ ê¸°ê¸° ë° êµ¬ê¸€ \n",
      "ì–´ì‹œìŠ¤í„´íŠ¸ë¥¼ ì ìš©í•œ êµ¬ê¸€ í”½ì…€(Pixel)ê³¼ ê²½ìŸí•  ê²ƒìœ¼ë¡œ ì˜ˆìƒ\n",
      "â˜ ì¶œì²˜ : ì‚¼ì„±ì „ì, â€˜ì‚¼ì„± AI í¬ëŸ¼â€™ì„œ ìì²´ ê°œë°œ ìƒì„±í˜• AI â€˜ì‚¼ì„± ê°€ìš°ìŠ¤â€™ ê³µê°œ, 2023.11.08.\n",
      "ì‚¼ì„±ì „ì, â€˜ì‚¼ì„± ê°œë°œì ì½˜í¼ëŸ°ìŠ¤ ì½”ë¦¬ì•„ 2023â€™ ê°œìµœ, 2023.11.14.\n",
      "TechRepublic, Samsung Gauss: Samsung Research Reveals Generative AI, 2023.11.08. (ì¶œì²˜: SPRI_AI_Brief_2023á„‚á…§á†«12á„‹á…¯á†¯á„’á…©_F.csv)\n",
      "3. í†µí•œ ê¸°ì—… ê³ ê°ì˜ í´ë¼ìš°ë“œ ì§€ì¶œ í™•ëŒ€ë¥¼ ìœ„í•´ AI íˆ¬ìë¥¼ ì§€ì†  \n",
      "âˆ™êµ¬ê¸€ì€ ì•¤ìŠ¤ë¡œí”½ ì™¸ì—ë„ AI ë™ì˜ìƒ ì œì‘ ë„êµ¬ë¥¼ ê°œë°œí•˜ëŠ” ëŸ°ì›¨ì´(Runway)ì™€ ì˜¤í”ˆì†ŒìŠ¤ ì†Œí”„íŠ¸ì›¨ì–´ \n",
      "ê¸°ì—… í—ˆê¹… í˜ì´ìŠ¤(Hugging Face)ì—ë„ íˆ¬ì\n",
      "âˆ™êµ¬ê¸€ì€ ì±—GPTì˜ ê¸°ë°˜ ê¸°ìˆ ê³¼ ì§ì ‘ ê²½ìŸí•  ìˆ˜ ìˆëŠ” ì°¨ì„¸ëŒ€ LLM â€˜ì œë¯¸ë‹ˆ(Gemini)â€™ë¥¼ í¬í•¨í•œ ìì²´ AI \n",
      "ì‹œìŠ¤í…œ ê°œë°œì—ë„ ìˆ˜ì‹­ì–µ ë‹¬ëŸ¬ë¥¼ íˆ¬ìí–ˆìœ¼ë©°, 2024ë…„ ì œë¯¸ë‹ˆë¥¼ ì¶œì‹œí•  ê³„íš\n",
      "â˜ ì¶œì²˜ : The Wall Street Journal, Google Commits $2 Billion in Funding to AI Startup Anthropic, 2023.10.27.\n",
      "Bloomberg, AI Startup Anthropic to Use Google Chips in Expanded Partnership, 2023.11.09. (ì¶œì²˜: SPRI_AI_Brief_2023á„‚á…§á†«12á„‹á…¯á†¯á„’á…©_F.csv)\n",
      "4. 16\n",
      "êµ¬ê¸€ ë”¥ë§ˆì¸ë“œ, ë²”ìš© AI ëª¨ë¸ì˜ ê¸°ëŠ¥ê³¼ ë™ì‘ì— ëŒ€í•œ ë¶„ë¥˜ ì²´ê³„ ë°œí‘œ\n",
      "n êµ¬ê¸€ ë”¥ë§ˆì¸ë“œ ì—°êµ¬ì§„ì´ ì„±ëŠ¥ê³¼ ë²”ìš©ì„±, ììœ¨ì„±ì„ ê¸°ì¤€ìœ¼ë¡œ ë²”ìš© AI(AGI)ì˜ ìˆ˜ì¤€ì„ \n",
      "0~5ë‹¨ê³„ê¹Œì§€ ì´ 6ë‹¨ê³„ë¡œ êµ¬ë¶„í•œ í”„ë ˆì„ì›Œí¬ë¥¼ ê³µê°œ\n",
      "n í˜„ì¬ AGIëŠ” ë‹¨ë°±ì§ˆ êµ¬ì¡°ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ì•ŒíŒŒí´ë“œì™€ ê°™ì€ íŠ¹ì • ìš©ë„ì—ì„œëŠ” 5ë‹¨ê³„ ìˆ˜ì¤€ì„ ë‹¬ì„±í–ˆì§€ë§Œ \n",
      "ê´‘ë²”ìœ„í•˜ê²Œ í™œìš©ë  ìˆ˜ ìˆëŠ” ë²”ìš©ì—ì„œëŠ” 1ë‹¨ê³„ ìˆ˜ì¤€ì— ë¨¸ë¬¼ëŸ¬ ìˆìŒ\n",
      "KEY Contents\n",
      "Â£ ì±—GPTì™€ êµ¬ê¸€ ë°”ë“œì™€ ê°™ì€ AI ì±—ë´‡ì€ ë²”ìš© AI 1ë‹¨ê³„ ìˆ˜ì¤€\n",
      "n êµ¬ê¸€ ë”¥ë§ˆì¸ë“œ ì—°êµ¬ì§„ì€ 2023ë…„ 11ì›” 4ì¼ ë²”ìš© AI(Artificial General Intelligence, AGI) ëª¨ë¸ì„ ìš©ë„ì™€ \n",
      "ì„±ëŠ¥ì— ë”°ë¼ ë¶„ë¥˜í•˜ëŠ” í”„ë ˆì„ì›Œí¬ë¥¼ ì œì‹œí•œ ë…¼ë¬¸ì„ ë°œí‘œ\n",
      "âˆ™í”„ë ˆì„ì›Œí¬ì˜ ëª©ì ì€ AGIì˜ ì„±ëŠ¥, ë²”ìš©ì„±, ììœ¨ì„± ìˆ˜ì¤€ì„ ì •ì˜í•˜ì—¬ ëª¨ë¸ ê°„ ë¹„êµì™€ ìœ„í—˜ í‰ê°€, AGI \n",
      "ë‹¬ì„±ê¹Œì§€ì˜ ì§„í–‰ ìƒí™©ì„ ì¸¡ì •í•  ìˆ˜ ìˆëŠ” ê³µí†µ ê¸°ì¤€ì„ ì œê³µí•˜ê¸° ìœ„í•¨\n",
      "n ì—°êµ¬ì§„ì€ AGI ê°œë… ì •ì˜ì— í•„ìš”í•œ ê¸°ì¤€ì„ ìˆ˜ë¦½í•˜ê¸° ìœ„í•œ 6ê°€ì§€ ì›ì¹™ì„ ì•„ë˜ì™€ ê°™ì´ ë„ì¶œ\n",
      "âˆ™(í”„ë¡œì„¸ìŠ¤ê°€ ì•„ë‹Œ ê¸°ëŠ¥ì— ì¤‘ì ) AIê°€ ì–´ë–»ê²Œ ì‘ë™í•˜ëŠ”ì§€ë³´ë‹¤ ë¬´ì—‡ì„ í•  ìˆ˜ ìˆëŠ”ì§€ê°€ ë” ì¤‘ìš”\n",
      "âˆ™(ë²”ìš©ì„±ê³¼ ì„±ëŠ¥ì„ ëª¨ë‘ í‰ê°€) ì§„ì •í•œ AGIëŠ” ì¸ê°„ì„ ëŠ¥ê°€í•˜ëŠ” í­ë„“ì€ ë²”ìš©ì„±ê³¼ ê¸°ìˆ ì˜ ê¹Šì´ë¥¼ ëª¨ë‘ ìš”êµ¬\n",
      "âˆ™(ì¸ì§€ì™€ ë©”íƒ€ì¸ì§€ ì‘ì—…ì— ì¤‘ì ) ë¬¼ë¦¬ì  ì‘ì—…ì˜ ìˆ˜í–‰ ëŠ¥ë ¥ì€ AGIì˜ í•„ìˆ˜ ì „ì œì¡°ê±´ì´ ì•„ë‹ˆë©°, ì¸ì§€ ì‘ì—…ê³¼ \n",
      "ë©”íƒ€ì¸ì§€ ì‘ì—…(ì˜ˆ; ìƒˆë¡œìš´ ì‘ì—…ì˜ í•™ìŠµ ëŠ¥ë ¥, ì¸ê°„ì—ê²Œ ë„ì›€ì„ ìš”ì²­í•  ì‹œì ì„ ì•„ëŠ” ëŠ¥ë ¥)ì´ í•µì‹¬\n",
      "âˆ™(ì‹¤ì œ êµ¬í˜„ë³´ë‹¤ ì ì¬ë ¥ì— ì§‘ì¤‘) í†µì œëœ ìƒí™©ì—ì„œ ë°œíœ˜ë˜ëŠ” ì„±ëŠ¥ì— ë”°ë¼ AGIë¥¼ ê·œì •í•˜ê³  í…ŒìŠ¤íŠ¸ë¥¼ ì§„í–‰ \n",
      "âˆ™(ìƒíƒœí•™ì  íƒ€ë‹¹ë„ë¥¼ ê°–ì¶˜ ë²¤ì¹˜ë§ˆí¬ ì‚¬ìš©) AGIì— ëŒ€í•œ ë²¤ì¹˜ë§ˆí¬ëŠ” ì‚¬ëŒë“¤ì´ ê²½ì œì Â· ì‚¬íšŒì  ë˜ëŠ” ì˜ˆìˆ ì ìœ¼ë¡œ \n",
      "ê°€ì¹˜ ìˆê²Œ ì—¬ê¸°ëŠ” ì‹¤ì§ˆì ì¸ ì‘ì—…ì„ ëŒ€ìƒìœ¼ë¡œ ì„±ëŠ¥ í‰ê°€ í•„ìš”\n",
      "âˆ™(ì¢…ì ì´ ì•„ë‹Œ AGIë¥¼ í–¥í•œ ê²½ë¡œì— ì¤‘ì ) ë‹¨ê³„ë³„ ì ‘ê·¼ë°©ì‹ì„ í†µí•´ AGIì˜ ë°œì „ ìƒíƒœë¥¼ ì ì§„ì ìœ¼ë¡œ ì¸¡ì • (ì¶œì²˜: SPRI_AI_Brief_2023á„‚á…§á†«12á„‹á…¯á†¯á„’á…©_F.csv)\n",
      "5. n ì—°êµ¬ì§„ì€ ìƒê¸° ì›ì¹™ì— ë”°ë¼ AIë¥¼ ì„±ëŠ¥ì— ë”°ë¼ 0~5ë‹¨ê³„ì™€ ê´‘ë²”ìœ„í•œ ëª©ì ì— í™œìš©ë  ìˆ˜ ìˆëŠ” ë²”ìš© AI ë° íŠ¹ì • \n",
      "ê³¼ì—…ì— í™œìš©ë˜ëŠ” íŠ¹ìˆ˜ AIë¡œ ë¶„ë¥˜í–ˆìœ¼ë©°, íŠ¹ìˆ˜ AIì—ì„œëŠ” 5ë‹¨ê³„ê¹Œì§€ ë‹¬ì„±ë˜ì—ˆìœ¼ë‚˜, ë²”ìš© AIëŠ” í˜„ì¬ 1ë‹¨ê³„ ìˆ˜ì¤€\n",
      "ì„±ëŠ¥\n",
      "íŠ¹ìˆ˜ AI ì˜ˆì‹œ\n",
      "ë²”ìš© AI ì˜ˆì‹œ\n",
      "0ë‹¨ê³„: AI ì•„ë‹˜\n",
      "ê³„ì‚°ê¸° ì†Œí”„íŠ¸ì›¨ì–´, ì»´íŒŒì¼ëŸ¬\n",
      "ì•„ë§ˆì¡´ ë©”ì»¤ë‹ˆì»¬ í„°í¬\n",
      "1ë‹¨ê³„: ì‹ ì§„(ìˆ™ë ¨ë˜ì§€ ì•Šì€ ì¸ê°„)\n",
      "GOFAI(Good Old Fashioned Artificial Intelligence) \n",
      "ì±—GPT, ë°”ë“œ, ë¼ë§ˆ2\n",
      "2ë‹¨ê³„: ìœ ëŠ¥(ìˆ™ë ¨ëœ ì¸ê°„ì˜ 50% ì´ìƒ)\n",
      "ìŠ¤ë§ˆíŠ¸ ìŠ¤í”¼ì»¤(ì• í”Œ ì‹œë¦¬, ì•„ë§ˆì¡´ ì•Œë ‰ì‚¬, êµ¬ê¸€ \n",
      "ì–´ì‹œìŠ¤í„´íŠ¸), IBM ì™“ìŠ¨ \n",
      "ë¯¸ë‹¬ì„±\n",
      "3ë‹¨ê³„: ì „ë¬¸ê°€(ìˆ™ë ¨ëœ ì¸ê°„ì˜ 90% ì´ìƒ)\n",
      "ë¬¸ë²• êµì •ê¸°(ê·¸ë˜ë¨¸ë¦¬), ìƒì„± ì´ë¯¸ì§€ ëª¨ë¸(ë‹¬ë¦¬2)\n",
      "ë¯¸ë‹¬ì„±\n",
      "4ë‹¨ê³„: ê±°ì¥(ìˆ™ë ¨ëœ ì¸ê°„ì˜ 99% ì´ìƒ) \n",
      "ë”¥ë¸”ë£¨, ì•ŒíŒŒê³ \n",
      "ë¯¸ë‹¬ì„±\n",
      "5ë‹¨ê³„: ì´ˆì¸ê°„(ì¸ê°„ì„ 100% ëŠ¥ê°€)\n",
      "ì•ŒíŒŒí´ë“œ, ì•ŒíŒŒì œë¡œ, ìŠ¤í†¡í”¼ì‹œ\n",
      "ë¯¸ë‹¬ì„±\n",
      "<êµ¬ê¸€ ë”¥ë§ˆì¸ë“œì˜ ë²”ìš© AI ë¶„ë¥˜ í”„ë ˆì„ì›Œí¬> \n",
      "â˜ ì¶œì²˜ : Arxiv.org, Levels of AGI: Operationalizing Progress on the Path to AGI, 2023.11.04. (ì¶œì²˜: SPRI_AI_Brief_2023á„‚á…§á†«12á„‹á…¯á†¯á„’á…©_F.csv)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(id='35bbb80f-2959-4bfd-b489-0afd3a96506f', metadata={'source': 'SPRI_AI_Brief_2023á„‚á…§á†«12á„‹á…¯á†¯á„’á…©_F.csv'}, page_content='SPRi AI Brief |  \\n2023-12ì›”í˜¸\\n10\\nì‚¼ì„±ì „ì, ìì²´ ê°œë°œ ìƒì„± AI â€˜ì‚¼ì„± ê°€ìš°ìŠ¤â€™ ê³µê°œ\\nn ì‚¼ì„±ì „ìê°€ ì˜¨ë””ë°”ì´ìŠ¤ì—ì„œ ì‘ë™ ê°€ëŠ¥í•˜ë©° ì–¸ì–´, ì½”ë“œ, ì´ë¯¸ì§€ì˜ 3ê°œ ëª¨ë¸ë¡œ êµ¬ì„±ëœ ìì²´ ê°œë°œ ìƒì„± \\nAI ëª¨ë¸ â€˜ì‚¼ì„± ê°€ìš°ìŠ¤â€™ë¥¼ ê³µê°œ\\nn ì‚¼ì„±ì „ìëŠ” ì‚¼ì„± ê°€ìš°ìŠ¤ë¥¼ ë‹¤ì–‘í•œ ì œí’ˆì— ë‹¨ê³„ì ìœ¼ë¡œ íƒ‘ì¬í•  ê³„íšìœ¼ë¡œ, ì˜¨ë””ë°”ì´ìŠ¤ ì‘ë™ì´ ê°€ëŠ¥í•œ \\nì‚¼ì„± ê°€ìš°ìŠ¤ëŠ” ì™¸ë¶€ë¡œ ì‚¬ìš©ì ì •ë³´ê°€ ìœ ì¶œë  ìœ„í—˜ì´ ì—†ë‹¤ëŠ” ì¥ì ì„ ë³´ìœ \\nKEY Contents\\nÂ£ ì–¸ì–´, ì½”ë“œ, ì´ë¯¸ì§€ì˜ 3ê°œ ëª¨ë¸ë¡œ êµ¬ì„±ëœ ì‚¼ì„± ê°€ìš°ìŠ¤, ì˜¨ë””ë°”ì´ìŠ¤ ì‘ë™ ì§€ì›\\nn ì‚¼ì„±ì „ìê°€ 2023ë…„ 11ì›” 8ì¼ ì—´ë¦° â€˜ì‚¼ì„± AI í¬ëŸ¼ 2023â€™ í–‰ì‚¬ì—ì„œ ìì²´ ê°œë°œí•œ ìƒì„± AI ëª¨ë¸ \\nâ€˜ì‚¼ì„± ê°€ìš°ìŠ¤â€™ë¥¼ ìµœì´ˆ ê³µê°œ\\nâˆ™ì •ê·œë¶„í¬ ì´ë¡ ì„ ì •ë¦½í•œ ì²œì¬ ìˆ˜í•™ì ê°€ìš°ìŠ¤(Gauss)ì˜ ì´ë¦„ì„ ë³¸ëœ¬ ì‚¼ì„± ê°€ìš°ìŠ¤ëŠ” ë‹¤ì–‘í•œ ìƒí™©ì— \\nìµœì í™”ëœ í¬ê¸°ì˜ ëª¨ë¸ ì„ íƒì´ ê°€ëŠ¥\\nâˆ™ì‚¼ì„± ê°€ìš°ìŠ¤ëŠ” ë¼ì´ì„ ìŠ¤ë‚˜ ê°œì¸ì •ë³´ë¥¼ ì¹¨í•´í•˜ì§€ ì•ŠëŠ” ì•ˆì „í•œ ë°ì´í„°ë¥¼ í†µí•´ í•™ìŠµë˜ì—ˆìœ¼ë©°, \\nì˜¨ë””ë°”ì´ìŠ¤ì—ì„œ ì‘ë™í•˜ë„ë¡ ì„¤ê³„ë˜ì–´ ì™¸ë¶€ë¡œ ì‚¬ìš©ìì˜ ì •ë³´ê°€ ìœ ì¶œë˜ì§€ ì•ŠëŠ” ì¥ì ì„ ë³´ìœ \\nâˆ™ì‚¼ì„±ì „ìëŠ” ì‚¼ì„± ê°€ìš°ìŠ¤ë¥¼ í™œìš©í•œ ì˜¨ë””ë°”ì´ìŠ¤ AI ê¸°ìˆ ë„ ì†Œê°œí–ˆìœ¼ë©°, ìƒì„± AI ëª¨ë¸ì„ ë‹¤ì–‘í•œ ì œí’ˆì— \\në‹¨ê³„ì ìœ¼ë¡œ íƒ‘ì¬í•  ê³„íš\\nn ì‚¼ì„± ê°€ìš°ìŠ¤ëŠ” â–³í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ì–¸ì–´ëª¨ë¸ â–³ì½”ë“œë¥¼ ìƒì„±í•˜ëŠ” ì½”ë“œ ëª¨ë¸ â–³ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ëŠ” \\nì´ë¯¸ì§€ ëª¨ë¸ì˜ 3ê°œ ëª¨ë¸ë¡œ êµ¬ì„±\\nâˆ™ì–¸ì–´ ëª¨ë¸ì€ í´ë¼ìš°ë“œì™€ ì˜¨ë””ë°”ì´ìŠ¤ ëŒ€ìƒ ë‹¤ì–‘í•œ ëª¨ë¸ë¡œ êµ¬ì„±ë˜ë©°, ë©”ì¼ ì‘ì„±, ë¬¸ì„œ ìš”ì•½, ë²ˆì—­ ì—…ë¬´ì˜ \\nì²˜ë¦¬ë¥¼ ì§€ì›\\nâˆ™ì½”ë“œ ëª¨ë¸ ê¸°ë°˜ì˜ AI ì½”ë”© ì–´ì‹œìŠ¤í„´íŠ¸ â€˜ì½”ë“œì•„ì´(code.i)â€™ëŠ” ëŒ€í™”í˜• ì¸í„°í˜ì´ìŠ¤ë¡œ ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•˜ë©° \\nì‚¬ë‚´ ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œì— ìµœì í™”\\nâˆ™ì´ë¯¸ì§€ ëª¨ë¸ì€ ì°½ì˜ì ì¸ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ê³  ê¸°ì¡´ ì´ë¯¸ì§€ë¥¼ ì›í•˜ëŠ” ëŒ€ë¡œ ë°”ê¿€ ìˆ˜ ìˆë„ë¡ ì§€ì›í•˜ë©° \\nì €í•´ìƒë„ ì´ë¯¸ì§€ì˜ ê³ í•´ìƒë„ ì „í™˜ë„ ì§€ì›\\nn IT ì „ë¬¸ì§€ í…Œí¬ë¦¬í¼ë¸”ë¦­(TechRepublic)ì€ ì˜¨ë””ë°”ì´ìŠ¤ AIê°€ ì£¼ìš” ê¸°ìˆ  íŠ¸ë Œë“œë¡œ ë¶€ìƒí–ˆë‹¤ë©°,'),\n",
       " Document(id='15a4fec5-fecb-4c1a-aa6f-e253a509152f', metadata={'source': 'SPRI_AI_Brief_2023á„‚á…§á†«12á„‹á…¯á†¯á„’á…©_F.csv'}, page_content='2024ë…„ë¶€í„° ê°€ìš°ìŠ¤ë¥¼ íƒ‘ì¬í•œ ì‚¼ì„± ìŠ¤ë§ˆíŠ¸í°ì´ ë©”íƒ€ì˜ ë¼ë§ˆ(Llama)2ë¥¼ íƒ‘ì¬í•œ í€„ì»´ ê¸°ê¸° ë° êµ¬ê¸€ \\nì–´ì‹œìŠ¤í„´íŠ¸ë¥¼ ì ìš©í•œ êµ¬ê¸€ í”½ì…€(Pixel)ê³¼ ê²½ìŸí•  ê²ƒìœ¼ë¡œ ì˜ˆìƒ\\nâ˜ ì¶œì²˜ : ì‚¼ì„±ì „ì, â€˜ì‚¼ì„± AI í¬ëŸ¼â€™ì„œ ìì²´ ê°œë°œ ìƒì„±í˜• AI â€˜ì‚¼ì„± ê°€ìš°ìŠ¤â€™ ê³µê°œ, 2023.11.08.\\nì‚¼ì„±ì „ì, â€˜ì‚¼ì„± ê°œë°œì ì½˜í¼ëŸ°ìŠ¤ ì½”ë¦¬ì•„ 2023â€™ ê°œìµœ, 2023.11.14.\\nTechRepublic, Samsung Gauss: Samsung Research Reveals Generative AI, 2023.11.08.'),\n",
       " Document(id='7b1d8bd5-85d6-4254-a291-5e27011d92d3', metadata={'source': 'SPRI_AI_Brief_2023á„‚á…§á†«12á„‹á…¯á†¯á„’á…©_F.csv'}, page_content='í†µí•œ ê¸°ì—… ê³ ê°ì˜ í´ë¼ìš°ë“œ ì§€ì¶œ í™•ëŒ€ë¥¼ ìœ„í•´ AI íˆ¬ìë¥¼ ì§€ì†  \\nâˆ™êµ¬ê¸€ì€ ì•¤ìŠ¤ë¡œí”½ ì™¸ì—ë„ AI ë™ì˜ìƒ ì œì‘ ë„êµ¬ë¥¼ ê°œë°œí•˜ëŠ” ëŸ°ì›¨ì´(Runway)ì™€ ì˜¤í”ˆì†ŒìŠ¤ ì†Œí”„íŠ¸ì›¨ì–´ \\nê¸°ì—… í—ˆê¹… í˜ì´ìŠ¤(Hugging Face)ì—ë„ íˆ¬ì\\nâˆ™êµ¬ê¸€ì€ ì±—GPTì˜ ê¸°ë°˜ ê¸°ìˆ ê³¼ ì§ì ‘ ê²½ìŸí•  ìˆ˜ ìˆëŠ” ì°¨ì„¸ëŒ€ LLM â€˜ì œë¯¸ë‹ˆ(Gemini)â€™ë¥¼ í¬í•¨í•œ ìì²´ AI \\nì‹œìŠ¤í…œ ê°œë°œì—ë„ ìˆ˜ì‹­ì–µ ë‹¬ëŸ¬ë¥¼ íˆ¬ìí–ˆìœ¼ë©°, 2024ë…„ ì œë¯¸ë‹ˆë¥¼ ì¶œì‹œí•  ê³„íš\\nâ˜ ì¶œì²˜ : The Wall Street Journal, Google Commits $2 Billion in Funding to AI Startup Anthropic, 2023.10.27.\\nBloomberg, AI Startup Anthropic to Use Google Chips in Expanded Partnership, 2023.11.09.'),\n",
       " Document(id='23e36641-f712-404c-aead-c0a6d920dfda', metadata={'source': 'SPRI_AI_Brief_2023á„‚á…§á†«12á„‹á…¯á†¯á„’á…©_F.csv'}, page_content='16\\nêµ¬ê¸€ ë”¥ë§ˆì¸ë“œ, ë²”ìš© AI ëª¨ë¸ì˜ ê¸°ëŠ¥ê³¼ ë™ì‘ì— ëŒ€í•œ ë¶„ë¥˜ ì²´ê³„ ë°œí‘œ\\nn êµ¬ê¸€ ë”¥ë§ˆì¸ë“œ ì—°êµ¬ì§„ì´ ì„±ëŠ¥ê³¼ ë²”ìš©ì„±, ììœ¨ì„±ì„ ê¸°ì¤€ìœ¼ë¡œ ë²”ìš© AI(AGI)ì˜ ìˆ˜ì¤€ì„ \\n0~5ë‹¨ê³„ê¹Œì§€ ì´ 6ë‹¨ê³„ë¡œ êµ¬ë¶„í•œ í”„ë ˆì„ì›Œí¬ë¥¼ ê³µê°œ\\nn í˜„ì¬ AGIëŠ” ë‹¨ë°±ì§ˆ êµ¬ì¡°ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ì•ŒíŒŒí´ë“œì™€ ê°™ì€ íŠ¹ì • ìš©ë„ì—ì„œëŠ” 5ë‹¨ê³„ ìˆ˜ì¤€ì„ ë‹¬ì„±í–ˆì§€ë§Œ \\nê´‘ë²”ìœ„í•˜ê²Œ í™œìš©ë  ìˆ˜ ìˆëŠ” ë²”ìš©ì—ì„œëŠ” 1ë‹¨ê³„ ìˆ˜ì¤€ì— ë¨¸ë¬¼ëŸ¬ ìˆìŒ\\nKEY Contents\\nÂ£ ì±—GPTì™€ êµ¬ê¸€ ë°”ë“œì™€ ê°™ì€ AI ì±—ë´‡ì€ ë²”ìš© AI 1ë‹¨ê³„ ìˆ˜ì¤€\\nn êµ¬ê¸€ ë”¥ë§ˆì¸ë“œ ì—°êµ¬ì§„ì€ 2023ë…„ 11ì›” 4ì¼ ë²”ìš© AI(Artificial General Intelligence, AGI) ëª¨ë¸ì„ ìš©ë„ì™€ \\nì„±ëŠ¥ì— ë”°ë¼ ë¶„ë¥˜í•˜ëŠ” í”„ë ˆì„ì›Œí¬ë¥¼ ì œì‹œí•œ ë…¼ë¬¸ì„ ë°œí‘œ\\nâˆ™í”„ë ˆì„ì›Œí¬ì˜ ëª©ì ì€ AGIì˜ ì„±ëŠ¥, ë²”ìš©ì„±, ììœ¨ì„± ìˆ˜ì¤€ì„ ì •ì˜í•˜ì—¬ ëª¨ë¸ ê°„ ë¹„êµì™€ ìœ„í—˜ í‰ê°€, AGI \\në‹¬ì„±ê¹Œì§€ì˜ ì§„í–‰ ìƒí™©ì„ ì¸¡ì •í•  ìˆ˜ ìˆëŠ” ê³µí†µ ê¸°ì¤€ì„ ì œê³µí•˜ê¸° ìœ„í•¨\\nn ì—°êµ¬ì§„ì€ AGI ê°œë… ì •ì˜ì— í•„ìš”í•œ ê¸°ì¤€ì„ ìˆ˜ë¦½í•˜ê¸° ìœ„í•œ 6ê°€ì§€ ì›ì¹™ì„ ì•„ë˜ì™€ ê°™ì´ ë„ì¶œ\\nâˆ™(í”„ë¡œì„¸ìŠ¤ê°€ ì•„ë‹Œ ê¸°ëŠ¥ì— ì¤‘ì ) AIê°€ ì–´ë–»ê²Œ ì‘ë™í•˜ëŠ”ì§€ë³´ë‹¤ ë¬´ì—‡ì„ í•  ìˆ˜ ìˆëŠ”ì§€ê°€ ë” ì¤‘ìš”\\nâˆ™(ë²”ìš©ì„±ê³¼ ì„±ëŠ¥ì„ ëª¨ë‘ í‰ê°€) ì§„ì •í•œ AGIëŠ” ì¸ê°„ì„ ëŠ¥ê°€í•˜ëŠ” í­ë„“ì€ ë²”ìš©ì„±ê³¼ ê¸°ìˆ ì˜ ê¹Šì´ë¥¼ ëª¨ë‘ ìš”êµ¬\\nâˆ™(ì¸ì§€ì™€ ë©”íƒ€ì¸ì§€ ì‘ì—…ì— ì¤‘ì ) ë¬¼ë¦¬ì  ì‘ì—…ì˜ ìˆ˜í–‰ ëŠ¥ë ¥ì€ AGIì˜ í•„ìˆ˜ ì „ì œì¡°ê±´ì´ ì•„ë‹ˆë©°, ì¸ì§€ ì‘ì—…ê³¼ \\në©”íƒ€ì¸ì§€ ì‘ì—…(ì˜ˆ; ìƒˆë¡œìš´ ì‘ì—…ì˜ í•™ìŠµ ëŠ¥ë ¥, ì¸ê°„ì—ê²Œ ë„ì›€ì„ ìš”ì²­í•  ì‹œì ì„ ì•„ëŠ” ëŠ¥ë ¥)ì´ í•µì‹¬\\nâˆ™(ì‹¤ì œ êµ¬í˜„ë³´ë‹¤ ì ì¬ë ¥ì— ì§‘ì¤‘) í†µì œëœ ìƒí™©ì—ì„œ ë°œíœ˜ë˜ëŠ” ì„±ëŠ¥ì— ë”°ë¼ AGIë¥¼ ê·œì •í•˜ê³  í…ŒìŠ¤íŠ¸ë¥¼ ì§„í–‰ \\nâˆ™(ìƒíƒœí•™ì  íƒ€ë‹¹ë„ë¥¼ ê°–ì¶˜ ë²¤ì¹˜ë§ˆí¬ ì‚¬ìš©) AGIì— ëŒ€í•œ ë²¤ì¹˜ë§ˆí¬ëŠ” ì‚¬ëŒë“¤ì´ ê²½ì œì Â· ì‚¬íšŒì  ë˜ëŠ” ì˜ˆìˆ ì ìœ¼ë¡œ \\nê°€ì¹˜ ìˆê²Œ ì—¬ê¸°ëŠ” ì‹¤ì§ˆì ì¸ ì‘ì—…ì„ ëŒ€ìƒìœ¼ë¡œ ì„±ëŠ¥ í‰ê°€ í•„ìš”\\nâˆ™(ì¢…ì ì´ ì•„ë‹Œ AGIë¥¼ í–¥í•œ ê²½ë¡œì— ì¤‘ì ) ë‹¨ê³„ë³„ ì ‘ê·¼ë°©ì‹ì„ í†µí•´ AGIì˜ ë°œì „ ìƒíƒœë¥¼ ì ì§„ì ìœ¼ë¡œ ì¸¡ì •'),\n",
       " Document(id='4be36b13-892d-4d3c-bc98-b38f8dbcf537', metadata={'source': 'SPRI_AI_Brief_2023á„‚á…§á†«12á„‹á…¯á†¯á„’á…©_F.csv'}, page_content='n ì—°êµ¬ì§„ì€ ìƒê¸° ì›ì¹™ì— ë”°ë¼ AIë¥¼ ì„±ëŠ¥ì— ë”°ë¼ 0~5ë‹¨ê³„ì™€ ê´‘ë²”ìœ„í•œ ëª©ì ì— í™œìš©ë  ìˆ˜ ìˆëŠ” ë²”ìš© AI ë° íŠ¹ì • \\nê³¼ì—…ì— í™œìš©ë˜ëŠ” íŠ¹ìˆ˜ AIë¡œ ë¶„ë¥˜í–ˆìœ¼ë©°, íŠ¹ìˆ˜ AIì—ì„œëŠ” 5ë‹¨ê³„ê¹Œì§€ ë‹¬ì„±ë˜ì—ˆìœ¼ë‚˜, ë²”ìš© AIëŠ” í˜„ì¬ 1ë‹¨ê³„ ìˆ˜ì¤€\\nì„±ëŠ¥\\níŠ¹ìˆ˜ AI ì˜ˆì‹œ\\në²”ìš© AI ì˜ˆì‹œ\\n0ë‹¨ê³„: AI ì•„ë‹˜\\nê³„ì‚°ê¸° ì†Œí”„íŠ¸ì›¨ì–´, ì»´íŒŒì¼ëŸ¬\\nì•„ë§ˆì¡´ ë©”ì»¤ë‹ˆì»¬ í„°í¬\\n1ë‹¨ê³„: ì‹ ì§„(ìˆ™ë ¨ë˜ì§€ ì•Šì€ ì¸ê°„)\\nGOFAI(Good Old Fashioned Artificial Intelligence) \\nì±—GPT, ë°”ë“œ, ë¼ë§ˆ2\\n2ë‹¨ê³„: ìœ ëŠ¥(ìˆ™ë ¨ëœ ì¸ê°„ì˜ 50% ì´ìƒ)\\nìŠ¤ë§ˆíŠ¸ ìŠ¤í”¼ì»¤(ì• í”Œ ì‹œë¦¬, ì•„ë§ˆì¡´ ì•Œë ‰ì‚¬, êµ¬ê¸€ \\nì–´ì‹œìŠ¤í„´íŠ¸), IBM ì™“ìŠ¨ \\në¯¸ë‹¬ì„±\\n3ë‹¨ê³„: ì „ë¬¸ê°€(ìˆ™ë ¨ëœ ì¸ê°„ì˜ 90% ì´ìƒ)\\në¬¸ë²• êµì •ê¸°(ê·¸ë˜ë¨¸ë¦¬), ìƒì„± ì´ë¯¸ì§€ ëª¨ë¸(ë‹¬ë¦¬2)\\në¯¸ë‹¬ì„±\\n4ë‹¨ê³„: ê±°ì¥(ìˆ™ë ¨ëœ ì¸ê°„ì˜ 99% ì´ìƒ) \\në”¥ë¸”ë£¨, ì•ŒíŒŒê³ \\në¯¸ë‹¬ì„±\\n5ë‹¨ê³„: ì´ˆì¸ê°„(ì¸ê°„ì„ 100% ëŠ¥ê°€)\\nì•ŒíŒŒí´ë“œ, ì•ŒíŒŒì œë¡œ, ìŠ¤í†¡í”¼ì‹œ\\në¯¸ë‹¬ì„±\\n<êµ¬ê¸€ ë”¥ë§ˆì¸ë“œì˜ ë²”ìš© AI ë¶„ë¥˜ í”„ë ˆì„ì›Œí¬> \\nâ˜ ì¶œì²˜ : Arxiv.org, Levels of AGI: Operationalizing Progress on the Path to AGI, 2023.11.04.')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def search_faiss_index(query, index_folder, file_name, top_k=5):\n",
    "    index_path = os.path.join(index_folder, file_name)\n",
    "    \n",
    "    # FAISS ì¸ë±ìŠ¤ ë¡œë“œ ì‹œ allow_dangerous_deserialization ì˜µì…˜ ì¶”ê°€\n",
    "    vector_store = FAISS.load_local(index_path, embedding_model, allow_dangerous_deserialization=True)\n",
    "    \n",
    "    query_embedding = embedding_model.embed_query(query)\n",
    "    results = vector_store.similarity_search_by_vector(query_embedding, k=top_k)\n",
    "    \n",
    "    print(f\"ğŸ” '{query}' ê²€ìƒ‰ ê²°ê³¼:\")\n",
    "    for i, result in enumerate(results):\n",
    "        print(f\"{i+1}. {result.page_content} (ì¶œì²˜: {result.metadata['source']})\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# search_faiss_index(\"í¬í•­ì—ì„œ ì—´ë¦¬ëŠ” ì¶•ì œì˜ ì´ë¦„ì€ ë¬´ì—‡ì¸ê°€?\", \"./faiss_index\", \"AIê¸°ë°˜_ì¸íŒŒë¶„ì„í”Œë«í¼êµ¬ì¶•_ì œì•ˆì„œ\")\n",
    "search_faiss_index(\"ì‚¼ì„±ì—ì„œ ë§Œë“  AIì˜ ì´ë¦„ì€ ë¬´ì—‡ì¸ê°€?\", \"./faiss_index\", \"SPRI_AI_Brief_2023ë…„12ì›”í˜¸_F\")\n",
    "# search_faiss_index(\"ê²½ê¸°ë„ ì¸êµ¬ì •ì±…ì‚¬ì—…ì—ì„œ í˜„í–‰ ìœ ì§€ í‰ê°€ë¥¼ ë°›ì€ ì‚¬ì—…ì˜ ê°œìˆ˜ëŠ”?\", \"./faiss_index\", \"2024ë…„ ê²½ê¸°ë„ ì¸êµ¬ì˜í–¥í‰ê°€_í¸ì§‘ë³¸\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
